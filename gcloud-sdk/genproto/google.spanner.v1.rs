// This file is @generated by prost-build.
/// Options to use for transactions.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct TransactionOptions {
    /// When `exclude_txn_from_change_streams` is set to `true`, it prevents read
    /// or write transactions from being tracked in change streams.
    ///
    /// * If the DDL option `allow_txn_exclusion` is set to `true`, then the
    ///   updates
    ///   made within this transaction aren't recorded in the change stream.
    ///
    /// * If you don't set the DDL option `allow_txn_exclusion` or if it's
    ///   set to `false`, then the updates made within this transaction are
    ///   recorded in the change stream.
    ///
    /// When `exclude_txn_from_change_streams` is set to `false` or not set,
    /// modifications from this transaction are recorded in all change streams
    /// that are tracking columns modified by these transactions.
    ///
    /// The `exclude_txn_from_change_streams` option can only be specified
    /// for read-write or partitioned DML transactions, otherwise the API returns
    /// an `INVALID_ARGUMENT` error.
    #[prost(bool, tag = "5")]
    pub exclude_txn_from_change_streams: bool,
    /// Isolation level for the transaction.
    #[prost(enumeration = "transaction_options::IsolationLevel", tag = "6")]
    pub isolation_level: i32,
    /// Required. The type of transaction.
    #[prost(oneof = "transaction_options::Mode", tags = "1, 3, 2")]
    pub mode: ::core::option::Option<transaction_options::Mode>,
}
/// Nested message and enum types in `TransactionOptions`.
pub mod transaction_options {
    /// Message type to initiate a read-write transaction. Currently this
    /// transaction type has no options.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ReadWrite {
        /// Read lock mode for the transaction.
        #[prost(enumeration = "read_write::ReadLockMode", tag = "1")]
        pub read_lock_mode: i32,
        /// Optional. Clients should pass the transaction ID of the previous
        /// transaction attempt that was aborted if this transaction is being
        /// executed on a multiplexed session.
        #[prost(bytes = "vec", tag = "2")]
        pub multiplexed_session_previous_transaction_id: ::prost::alloc::vec::Vec<u8>,
    }
    /// Nested message and enum types in `ReadWrite`.
    pub mod read_write {
        /// `ReadLockMode` is used to set the read lock mode for read-write
        /// transactions.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum ReadLockMode {
            /// Default value.
            ///
            /// * If isolation level is
            ///   \[REPEATABLE_READ\]\[google.spanner.v1.TransactionOptions.IsolationLevel.REPEATABLE_READ\],
            ///   then it is an error to specify `read_lock_mode`. Locking semantics
            ///   default to `OPTIMISTIC`. No validation checks are done for reads,
            ///   except to validate that the data that was served at the snapshot time
            ///   is unchanged at commit time in the following cases:
            ///   1. reads done as part of queries that use `SELECT FOR UPDATE`
            ///   1. reads done as part of statements with a `LOCK_SCANNED_RANGES`
            ///      hint
            ///   1. reads done as part of DML statements
            /// * At all other isolation levels, if `read_lock_mode` is the default
            ///   value, then pessimistic read locks are used.
            Unspecified = 0,
            /// Pessimistic lock mode.
            ///
            /// Read locks are acquired immediately on read.
            /// Semantics described only applies to
            /// \[SERIALIZABLE\]\[google.spanner.v1.TransactionOptions.IsolationLevel.SERIALIZABLE\]
            /// isolation.
            Pessimistic = 1,
            /// Optimistic lock mode.
            ///
            /// Locks for reads within the transaction are not acquired on read.
            /// Instead the locks are acquired on a commit to validate that
            /// read/queried data has not changed since the transaction started.
            /// Semantics described only applies to
            /// \[SERIALIZABLE\]\[google.spanner.v1.TransactionOptions.IsolationLevel.SERIALIZABLE\]
            /// isolation.
            Optimistic = 2,
        }
        impl ReadLockMode {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "READ_LOCK_MODE_UNSPECIFIED",
                    Self::Pessimistic => "PESSIMISTIC",
                    Self::Optimistic => "OPTIMISTIC",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "READ_LOCK_MODE_UNSPECIFIED" => Some(Self::Unspecified),
                    "PESSIMISTIC" => Some(Self::Pessimistic),
                    "OPTIMISTIC" => Some(Self::Optimistic),
                    _ => None,
                }
            }
        }
    }
    /// Message type to initiate a Partitioned DML transaction.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct PartitionedDml {}
    /// Message type to initiate a read-only transaction.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ReadOnly {
        /// If true, the Cloud Spanner-selected read timestamp is included in
        /// the \[Transaction\]\[google.spanner.v1.Transaction\] message that describes
        /// the transaction.
        #[prost(bool, tag = "6")]
        pub return_read_timestamp: bool,
        /// How to choose the timestamp for the read-only transaction.
        #[prost(oneof = "read_only::TimestampBound", tags = "1, 2, 3, 4, 5")]
        pub timestamp_bound: ::core::option::Option<read_only::TimestampBound>,
    }
    /// Nested message and enum types in `ReadOnly`.
    pub mod read_only {
        /// How to choose the timestamp for the read-only transaction.
        #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum TimestampBound {
            /// Read at a timestamp where all previously committed transactions
            /// are visible.
            #[prost(bool, tag = "1")]
            Strong(bool),
            /// Executes all reads at a timestamp >= `min_read_timestamp`.
            ///
            /// This is useful for requesting fresher data than some previous
            /// read, or data that is fresh enough to observe the effects of some
            /// previously committed transaction whose timestamp is known.
            ///
            /// Note that this option can only be used in single-use transactions.
            ///
            /// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
            /// Example: `"2014-10-02T15:01:23.045123456Z"`.
            #[prost(message, tag = "2")]
            MinReadTimestamp(::prost_types::Timestamp),
            /// Read data at a timestamp >= `NOW - max_staleness`
            /// seconds. Guarantees that all writes that have committed more
            /// than the specified number of seconds ago are visible. Because
            /// Cloud Spanner chooses the exact timestamp, this mode works even if
            /// the client's local clock is substantially skewed from Cloud Spanner
            /// commit timestamps.
            ///
            /// Useful for reading the freshest data available at a nearby
            /// replica, while bounding the possible staleness if the local
            /// replica has fallen behind.
            ///
            /// Note that this option can only be used in single-use
            /// transactions.
            #[prost(message, tag = "3")]
            MaxStaleness(::prost_types::Duration),
            /// Executes all reads at the given timestamp. Unlike other modes,
            /// reads at a specific timestamp are repeatable; the same read at
            /// the same timestamp always returns the same data. If the
            /// timestamp is in the future, the read is blocked until the
            /// specified timestamp, modulo the read's deadline.
            ///
            /// Useful for large scale consistent reads such as mapreduces, or
            /// for coordinating many reads against a consistent snapshot of the
            /// data.
            ///
            /// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
            /// Example: `"2014-10-02T15:01:23.045123456Z"`.
            #[prost(message, tag = "4")]
            ReadTimestamp(::prost_types::Timestamp),
            /// Executes all reads at a timestamp that is `exact_staleness`
            /// old. The timestamp is chosen soon after the read is started.
            ///
            /// Guarantees that all writes that have committed more than the
            /// specified number of seconds ago are visible. Because Cloud Spanner
            /// chooses the exact timestamp, this mode works even if the client's
            /// local clock is substantially skewed from Cloud Spanner commit
            /// timestamps.
            ///
            /// Useful for reading at nearby replicas without the distributed
            /// timestamp negotiation overhead of `max_staleness`.
            #[prost(message, tag = "5")]
            ExactStaleness(::prost_types::Duration),
        }
    }
    /// `IsolationLevel` is used when setting `isolation_level` for a transaction.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum IsolationLevel {
        /// Default value.
        ///
        /// If the value is not specified, the `SERIALIZABLE` isolation level is
        /// used.
        Unspecified = 0,
        /// All transactions appear as if they executed in a serial order, even if
        /// some of the reads, writes, and other operations of distinct transactions
        /// actually occurred in parallel. Spanner assigns commit timestamps that
        /// reflect the order of committed transactions to implement this property.
        /// Spanner offers a stronger guarantee than serializability called external
        /// consistency. For further details, please refer to
        /// <https://cloud.google.com/spanner/docs/true-time-external-consistency#serializability.>
        Serializable = 1,
        /// All reads performed during the transaction observe a consistent snapshot
        /// of the database, and the transaction is only successfully committed in
        /// the absence of conflicts between its updates and any concurrent updates
        /// that have occurred since that snapshot. Consequently, in contrast to
        /// `SERIALIZABLE` transactions, only write-write conflicts are detected in
        /// snapshot transactions.
        ///
        /// This isolation level does not support Read-only and Partitioned DML
        /// transactions.
        ///
        /// When `REPEATABLE_READ` is specified on a read-write transaction, the
        /// locking semantics default to `OPTIMISTIC`.
        RepeatableRead = 2,
    }
    impl IsolationLevel {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "ISOLATION_LEVEL_UNSPECIFIED",
                Self::Serializable => "SERIALIZABLE",
                Self::RepeatableRead => "REPEATABLE_READ",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "ISOLATION_LEVEL_UNSPECIFIED" => Some(Self::Unspecified),
                "SERIALIZABLE" => Some(Self::Serializable),
                "REPEATABLE_READ" => Some(Self::RepeatableRead),
                _ => None,
            }
        }
    }
    /// Required. The type of transaction.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Mode {
        /// Transaction may write.
        ///
        /// Authorization to begin a read-write transaction requires
        /// `spanner.databases.beginOrRollbackReadWriteTransaction` permission
        /// on the `session` resource.
        #[prost(message, tag = "1")]
        ReadWrite(ReadWrite),
        /// Partitioned DML transaction.
        ///
        /// Authorization to begin a Partitioned DML transaction requires
        /// `spanner.databases.beginPartitionedDmlTransaction` permission
        /// on the `session` resource.
        #[prost(message, tag = "3")]
        PartitionedDml(PartitionedDml),
        /// Transaction does not write.
        ///
        /// Authorization to begin a read-only transaction requires
        /// `spanner.databases.beginReadOnlyTransaction` permission
        /// on the `session` resource.
        #[prost(message, tag = "2")]
        ReadOnly(ReadOnly),
    }
}
/// A transaction.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Transaction {
    /// `id` may be used to identify the transaction in subsequent
    /// \[Read\]\[google.spanner.v1.Spanner.Read\],
    /// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\],
    /// \[Commit\]\[google.spanner.v1.Spanner.Commit\], or
    /// \[Rollback\]\[google.spanner.v1.Spanner.Rollback\] calls.
    ///
    /// Single-use read-only transactions do not have IDs, because
    /// single-use transactions do not support multiple requests.
    #[prost(bytes = "vec", tag = "1")]
    pub id: ::prost::alloc::vec::Vec<u8>,
    /// For snapshot read-only transactions, the read timestamp chosen
    /// for the transaction. Not returned by default: see
    /// \[TransactionOptions.ReadOnly.return_read_timestamp\]\[google.spanner.v1.TransactionOptions.ReadOnly.return_read_timestamp\].
    ///
    /// A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
    /// Example: `"2014-10-02T15:01:23.045123456Z"`.
    #[prost(message, optional, tag = "2")]
    pub read_timestamp: ::core::option::Option<::prost_types::Timestamp>,
    /// A precommit token is included in the response of a BeginTransaction
    /// request if the read-write transaction is on a multiplexed session and
    /// a mutation_key was specified in the
    /// \[BeginTransaction\]\[google.spanner.v1.BeginTransactionRequest\].
    /// The precommit token with the highest sequence number from this transaction
    /// attempt should be passed to the \[Commit\]\[google.spanner.v1.Spanner.Commit\]
    /// request for this transaction.
    #[prost(message, optional, tag = "3")]
    pub precommit_token: ::core::option::Option<MultiplexedSessionPrecommitToken>,
}
/// This message is used to select the transaction in which a
/// \[Read\]\[google.spanner.v1.Spanner.Read\] or
/// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\] call runs.
///
/// See \[TransactionOptions\]\[google.spanner.v1.TransactionOptions\] for more
/// information about transactions.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct TransactionSelector {
    /// If no fields are set, the default is a single use transaction
    /// with strong concurrency.
    #[prost(oneof = "transaction_selector::Selector", tags = "1, 2, 3")]
    pub selector: ::core::option::Option<transaction_selector::Selector>,
}
/// Nested message and enum types in `TransactionSelector`.
pub mod transaction_selector {
    /// If no fields are set, the default is a single use transaction
    /// with strong concurrency.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Selector {
        /// Execute the read or SQL query in a temporary transaction.
        /// This is the most efficient way to execute a transaction that
        /// consists of a single SQL query.
        #[prost(message, tag = "1")]
        SingleUse(super::TransactionOptions),
        /// Execute the read or SQL query in a previously-started transaction.
        #[prost(bytes, tag = "2")]
        Id(::prost::alloc::vec::Vec<u8>),
        /// Begin a new transaction and execute this read or SQL query in
        /// it. The transaction ID of the new transaction is returned in
        /// \[ResultSetMetadata.transaction\]\[google.spanner.v1.ResultSetMetadata.transaction\],
        /// which is a \[Transaction\]\[google.spanner.v1.Transaction\].
        #[prost(message, tag = "3")]
        Begin(super::TransactionOptions),
    }
}
/// When a read-write transaction is executed on a multiplexed session,
/// this precommit token is sent back to the client
/// as a part of the \[Transaction\]\[google.spanner.v1.Transaction\] message in the
/// \[BeginTransaction\]\[google.spanner.v1.BeginTransactionRequest\] response and
/// also as a part of the \[ResultSet\]\[google.spanner.v1.ResultSet\] and
/// \[PartialResultSet\]\[google.spanner.v1.PartialResultSet\] responses.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct MultiplexedSessionPrecommitToken {
    /// Opaque precommit token.
    #[prost(bytes = "vec", tag = "1")]
    pub precommit_token: ::prost::alloc::vec::Vec<u8>,
    /// An incrementing seq number is generated on every precommit token
    /// that is returned. Clients should remember the precommit token with the
    /// highest sequence number from the current transaction attempt.
    #[prost(int32, tag = "2")]
    pub seq_num: i32,
}
/// The response for \[Commit\]\[google.spanner.v1.Spanner.Commit\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CommitResponse {
    /// The Cloud Spanner timestamp at which the transaction committed.
    #[prost(message, optional, tag = "1")]
    pub commit_timestamp: ::core::option::Option<::prost_types::Timestamp>,
    /// The statistics about this `Commit`. Not returned by default.
    /// For more information, see
    /// \[CommitRequest.return_commit_stats\]\[google.spanner.v1.CommitRequest.return_commit_stats\].
    #[prost(message, optional, tag = "2")]
    pub commit_stats: ::core::option::Option<commit_response::CommitStats>,
    /// If `TransactionOptions.isolation_level` is set to
    /// `IsolationLevel.REPEATABLE_READ`, then the snapshot timestamp is the
    /// timestamp at which all reads in the transaction ran. This timestamp is
    /// never returned.
    #[prost(message, optional, tag = "5")]
    pub snapshot_timestamp: ::core::option::Option<::prost_types::Timestamp>,
    /// You must examine and retry the commit if the following is populated.
    #[prost(oneof = "commit_response::MultiplexedSessionRetry", tags = "4")]
    pub multiplexed_session_retry: ::core::option::Option<
        commit_response::MultiplexedSessionRetry,
    >,
}
/// Nested message and enum types in `CommitResponse`.
pub mod commit_response {
    /// Additional statistics about a commit.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct CommitStats {
        /// The total number of mutations for the transaction. Knowing the
        /// `mutation_count` value can help you maximize the number of mutations
        /// in a transaction and minimize the number of API round trips. You can
        /// also monitor this value to prevent transactions from exceeding the system
        /// [limit](<https://cloud.google.com/spanner/quotas#limits_for_creating_reading_updating_and_deleting_data>).
        /// If the number of mutations exceeds the limit, the server returns
        /// [INVALID_ARGUMENT](<https://cloud.google.com/spanner/docs/reference/rest/v1/Code#ENUM_VALUES.INVALID_ARGUMENT>).
        #[prost(int64, tag = "1")]
        pub mutation_count: i64,
    }
    /// You must examine and retry the commit if the following is populated.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum MultiplexedSessionRetry {
        /// If specified, transaction has not committed yet.
        /// You must retry the commit with the new precommit token.
        #[prost(message, tag = "4")]
        PrecommitToken(super::MultiplexedSessionPrecommitToken),
    }
}
/// KeyRange represents a range of rows in a table or index.
///
/// A range has a start key and an end key. These keys can be open or
/// closed, indicating if the range includes rows with that key.
///
/// Keys are represented by lists, where the ith value in the list
/// corresponds to the ith component of the table or index primary key.
/// Individual values are encoded as described
/// \[here\]\[google.spanner.v1.TypeCode\].
///
/// For example, consider the following table definition:
///
/// ```text
/// CREATE TABLE UserEvents (
///    UserName STRING(MAX),
///    EventDate STRING(10)
/// ) PRIMARY KEY(UserName, EventDate);
/// ```
///
/// The following keys name rows in this table:
///
/// ```text
/// \["Bob", "2014-09-23"\]
/// \["Alfred", "2015-06-12"\]
/// ```
///
/// Since the `UserEvents` table's `PRIMARY KEY` clause names two
/// columns, each `UserEvents` key has two elements; the first is the
/// `UserName`, and the second is the `EventDate`.
///
/// Key ranges with multiple components are interpreted
/// lexicographically by component using the table or index key's declared
/// sort order. For example, the following range returns all events for
/// user `"Bob"` that occurred in the year 2015:
///
/// ```text
/// "start_closed": \["Bob", "2015-01-01"\]
/// "end_closed": \["Bob", "2015-12-31"\]
/// ```
///
/// Start and end keys can omit trailing key components. This affects the
/// inclusion and exclusion of rows that exactly match the provided key
/// components: if the key is closed, then rows that exactly match the
/// provided components are included; if the key is open, then rows
/// that exactly match are not included.
///
/// For example, the following range includes all events for `"Bob"` that
/// occurred during and after the year 2000:
///
/// ```text
/// "start_closed": \["Bob", "2000-01-01"\]
/// "end_closed": \["Bob"\]
/// ```
///
/// The next example retrieves all events for `"Bob"`:
///
/// ```text
/// "start_closed": \["Bob"\]
/// "end_closed": \["Bob"\]
/// ```
///
/// To retrieve events before the year 2000:
///
/// ```text
/// "start_closed": \["Bob"\]
/// "end_open": \["Bob", "2000-01-01"\]
/// ```
///
/// The following range includes all rows in the table:
///
/// ```text
/// "start_closed": \[\]
/// "end_closed": \[\]
/// ```
///
/// This range returns all users whose `UserName` begins with any
/// character from A to C:
///
/// ```text
/// "start_closed": \["A"\]
/// "end_open": \["D"\]
/// ```
///
/// This range returns all users whose `UserName` begins with B:
///
/// ```text
/// "start_closed": \["B"\]
/// "end_open": \["C"\]
/// ```
///
/// Key ranges honor column sort order. For example, suppose a table is
/// defined as follows:
///
/// ```text
/// CREATE TABLE DescendingSortedTable {
///    Key INT64,
///    ...
/// ) PRIMARY KEY(Key DESC);
/// ```
///
/// The following range retrieves all rows with key values between 1
/// and 100 inclusive:
///
/// ```text
/// "start_closed": \["100"\]
/// "end_closed": \["1"\]
/// ```
///
/// Note that 100 is passed as the start, and 1 is passed as the end,
/// because `Key` is a descending column in the schema.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct KeyRange {
    /// The start key must be provided. It can be either closed or open.
    #[prost(oneof = "key_range::StartKeyType", tags = "1, 2")]
    pub start_key_type: ::core::option::Option<key_range::StartKeyType>,
    /// The end key must be provided. It can be either closed or open.
    #[prost(oneof = "key_range::EndKeyType", tags = "3, 4")]
    pub end_key_type: ::core::option::Option<key_range::EndKeyType>,
}
/// Nested message and enum types in `KeyRange`.
pub mod key_range {
    /// The start key must be provided. It can be either closed or open.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum StartKeyType {
        /// If the start is closed, then the range includes all rows whose
        /// first `len(start_closed)` key columns exactly match `start_closed`.
        #[prost(message, tag = "1")]
        StartClosed(::prost_types::ListValue),
        /// If the start is open, then the range excludes rows whose first
        /// `len(start_open)` key columns exactly match `start_open`.
        #[prost(message, tag = "2")]
        StartOpen(::prost_types::ListValue),
    }
    /// The end key must be provided. It can be either closed or open.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum EndKeyType {
        /// If the end is closed, then the range includes all rows whose
        /// first `len(end_closed)` key columns exactly match `end_closed`.
        #[prost(message, tag = "3")]
        EndClosed(::prost_types::ListValue),
        /// If the end is open, then the range excludes rows whose first
        /// `len(end_open)` key columns exactly match `end_open`.
        #[prost(message, tag = "4")]
        EndOpen(::prost_types::ListValue),
    }
}
/// `KeySet` defines a collection of Cloud Spanner keys and/or key ranges. All
/// the keys are expected to be in the same table or index. The keys need
/// not be sorted in any particular way.
///
/// If the same key is specified multiple times in the set (for example
/// if two ranges, two keys, or a key and a range overlap), Cloud Spanner
/// behaves as if the key were only specified once.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct KeySet {
    /// A list of specific keys. Entries in `keys` should have exactly as
    /// many elements as there are columns in the primary or index key
    /// with which this `KeySet` is used.  Individual key values are
    /// encoded as described \[here\]\[google.spanner.v1.TypeCode\].
    #[prost(message, repeated, tag = "1")]
    pub keys: ::prost::alloc::vec::Vec<::prost_types::ListValue>,
    /// A list of key ranges. See \[KeyRange\]\[google.spanner.v1.KeyRange\] for more information about
    /// key range specifications.
    #[prost(message, repeated, tag = "2")]
    pub ranges: ::prost::alloc::vec::Vec<KeyRange>,
    /// For convenience `all` can be set to `true` to indicate that this
    /// `KeySet` matches all keys in the table or index. Note that any keys
    /// specified in `keys` or `ranges` are only yielded once.
    #[prost(bool, tag = "3")]
    pub all: bool,
}
/// A modification to one or more Cloud Spanner rows.  Mutations can be
/// applied to a Cloud Spanner database by sending them in a
/// \[Commit\]\[google.spanner.v1.Spanner.Commit\] call.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Mutation {
    /// Required. The operation to perform.
    #[prost(oneof = "mutation::Operation", tags = "1, 2, 3, 4, 5")]
    pub operation: ::core::option::Option<mutation::Operation>,
}
/// Nested message and enum types in `Mutation`.
pub mod mutation {
    /// Arguments to \[insert\]\[google.spanner.v1.Mutation.insert\], \[update\]\[google.spanner.v1.Mutation.update\], \[insert_or_update\]\[google.spanner.v1.Mutation.insert_or_update\], and
    /// \[replace\]\[google.spanner.v1.Mutation.replace\] operations.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Write {
        /// Required. The table whose rows will be written.
        #[prost(string, tag = "1")]
        pub table: ::prost::alloc::string::String,
        /// The names of the columns in \[table\]\[google.spanner.v1.Mutation.Write.table\] to be written.
        ///
        /// The list of columns must contain enough columns to allow
        /// Cloud Spanner to derive values for all primary key columns in the
        /// row(s) to be modified.
        #[prost(string, repeated, tag = "2")]
        pub columns: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
        /// The values to be written. `values` can contain more than one
        /// list of values. If it does, then multiple rows are written, one
        /// for each entry in `values`. Each list in `values` must have
        /// exactly as many entries as there are entries in \[columns\]\[google.spanner.v1.Mutation.Write.columns\]
        /// above. Sending multiple lists is equivalent to sending multiple
        /// `Mutation`s, each containing one `values` entry and repeating
        /// \[table\]\[google.spanner.v1.Mutation.Write.table\] and \[columns\]\[google.spanner.v1.Mutation.Write.columns\]. Individual values in each list are
        /// encoded as described \[here\]\[google.spanner.v1.TypeCode\].
        #[prost(message, repeated, tag = "3")]
        pub values: ::prost::alloc::vec::Vec<::prost_types::ListValue>,
    }
    /// Arguments to \[delete\]\[google.spanner.v1.Mutation.delete\] operations.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Delete {
        /// Required. The table whose rows will be deleted.
        #[prost(string, tag = "1")]
        pub table: ::prost::alloc::string::String,
        /// Required. The primary keys of the rows within \[table\]\[google.spanner.v1.Mutation.Delete.table\] to delete.  The
        /// primary keys must be specified in the order in which they appear in the
        /// `PRIMARY KEY()` clause of the table's equivalent DDL statement (the DDL
        /// statement used to create the table).
        /// Delete is idempotent. The transaction will succeed even if some or all
        /// rows do not exist.
        #[prost(message, optional, tag = "2")]
        pub key_set: ::core::option::Option<super::KeySet>,
    }
    /// Required. The operation to perform.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Operation {
        /// Insert new rows in a table. If any of the rows already exist,
        /// the write or transaction fails with error `ALREADY_EXISTS`.
        #[prost(message, tag = "1")]
        Insert(Write),
        /// Update existing rows in a table. If any of the rows does not
        /// already exist, the transaction fails with error `NOT_FOUND`.
        #[prost(message, tag = "2")]
        Update(Write),
        /// Like \[insert\]\[google.spanner.v1.Mutation.insert\], except that if the row already exists, then
        /// its column values are overwritten with the ones provided. Any
        /// column values not explicitly written are preserved.
        ///
        /// When using \[insert_or_update\]\[google.spanner.v1.Mutation.insert_or_update\], just as when using \[insert\]\[google.spanner.v1.Mutation.insert\], all `NOT  NULL` columns in the table must be given a value. This holds true
        /// even when the row already exists and will therefore actually be updated.
        #[prost(message, tag = "3")]
        InsertOrUpdate(Write),
        /// Like \[insert\]\[google.spanner.v1.Mutation.insert\], except that if the row already exists, it is
        /// deleted, and the column values provided are inserted
        /// instead. Unlike \[insert_or_update\]\[google.spanner.v1.Mutation.insert_or_update\], this means any values not
        /// explicitly written become `NULL`.
        ///
        /// In an interleaved table, if you create the child table with the
        /// `ON DELETE CASCADE` annotation, then replacing a parent row
        /// also deletes the child rows. Otherwise, you must delete the
        /// child rows before you replace the parent row.
        #[prost(message, tag = "4")]
        Replace(Write),
        /// Delete rows from a table. Succeeds whether or not the named
        /// rows were present.
        #[prost(message, tag = "5")]
        Delete(Delete),
    }
}
/// Node information for nodes appearing in a \[QueryPlan.plan_nodes\]\[google.spanner.v1.QueryPlan.plan_nodes\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PlanNode {
    /// The `PlanNode`'s index in \[node list\]\[google.spanner.v1.QueryPlan.plan_nodes\].
    #[prost(int32, tag = "1")]
    pub index: i32,
    /// Used to determine the type of node. May be needed for visualizing
    /// different kinds of nodes differently. For example, If the node is a
    /// \[SCALAR\]\[google.spanner.v1.PlanNode.Kind.SCALAR\] node, it will have a condensed representation
    /// which can be used to directly embed a description of the node in its
    /// parent.
    #[prost(enumeration = "plan_node::Kind", tag = "2")]
    pub kind: i32,
    /// The display name for the node.
    #[prost(string, tag = "3")]
    pub display_name: ::prost::alloc::string::String,
    /// List of child node `index`es and their relationship to this parent.
    #[prost(message, repeated, tag = "4")]
    pub child_links: ::prost::alloc::vec::Vec<plan_node::ChildLink>,
    /// Condensed representation for \[SCALAR\]\[google.spanner.v1.PlanNode.Kind.SCALAR\] nodes.
    #[prost(message, optional, tag = "5")]
    pub short_representation: ::core::option::Option<plan_node::ShortRepresentation>,
    /// Attributes relevant to the node contained in a group of key-value pairs.
    /// For example, a Parameter Reference node could have the following
    /// information in its metadata:
    ///
    /// ```text
    /// {
    ///    "parameter_reference": "param1",
    ///    "parameter_type": "array"
    /// }
    /// ```
    #[prost(message, optional, tag = "6")]
    pub metadata: ::core::option::Option<::prost_types::Struct>,
    /// The execution statistics associated with the node, contained in a group of
    /// key-value pairs. Only present if the plan was returned as a result of a
    /// profile query. For example, number of executions, number of rows/time per
    /// execution etc.
    #[prost(message, optional, tag = "7")]
    pub execution_stats: ::core::option::Option<::prost_types::Struct>,
}
/// Nested message and enum types in `PlanNode`.
pub mod plan_node {
    /// Metadata associated with a parent-child relationship appearing in a
    /// \[PlanNode\]\[google.spanner.v1.PlanNode\].
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ChildLink {
        /// The node to which the link points.
        #[prost(int32, tag = "1")]
        pub child_index: i32,
        /// The type of the link. For example, in Hash Joins this could be used to
        /// distinguish between the build child and the probe child, or in the case
        /// of the child being an output variable, to represent the tag associated
        /// with the output variable.
        #[prost(string, tag = "2")]
        pub r#type: ::prost::alloc::string::String,
        /// Only present if the child node is \[SCALAR\]\[google.spanner.v1.PlanNode.Kind.SCALAR\] and corresponds
        /// to an output variable of the parent node. The field carries the name of
        /// the output variable.
        /// For example, a `TableScan` operator that reads rows from a table will
        /// have child links to the `SCALAR` nodes representing the output variables
        /// created for each column that is read by the operator. The corresponding
        /// `variable` fields will be set to the variable names assigned to the
        /// columns.
        #[prost(string, tag = "3")]
        pub variable: ::prost::alloc::string::String,
    }
    /// Condensed representation of a node and its subtree. Only present for
    /// `SCALAR` \[PlanNode(s)\]\[google.spanner.v1.PlanNode\].
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct ShortRepresentation {
        /// A string representation of the expression subtree rooted at this node.
        #[prost(string, tag = "1")]
        pub description: ::prost::alloc::string::String,
        /// A mapping of (subquery variable name) -> (subquery node id) for cases
        /// where the `description` string of this node references a `SCALAR`
        /// subquery contained in the expression subtree rooted at this node. The
        /// referenced `SCALAR` subquery may not necessarily be a direct child of
        /// this node.
        #[prost(map = "string, int32", tag = "2")]
        pub subqueries: ::std::collections::HashMap<::prost::alloc::string::String, i32>,
    }
    /// The kind of \[PlanNode\]\[google.spanner.v1.PlanNode\]. Distinguishes between the two different kinds of
    /// nodes that can appear in a query plan.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Kind {
        /// Not specified.
        Unspecified = 0,
        /// Denotes a Relational operator node in the expression tree. Relational
        /// operators represent iterative processing of rows during query execution.
        /// For example, a `TableScan` operation that reads rows from a table.
        Relational = 1,
        /// Denotes a Scalar node in the expression tree. Scalar nodes represent
        /// non-iterable entities in the query plan. For example, constants or
        /// arithmetic operators appearing inside predicate expressions or references
        /// to column names.
        Scalar = 2,
    }
    impl Kind {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "KIND_UNSPECIFIED",
                Self::Relational => "RELATIONAL",
                Self::Scalar => "SCALAR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "KIND_UNSPECIFIED" => Some(Self::Unspecified),
                "RELATIONAL" => Some(Self::Relational),
                "SCALAR" => Some(Self::Scalar),
                _ => None,
            }
        }
    }
}
/// Contains an ordered list of nodes appearing in the query plan.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct QueryPlan {
    /// The nodes in the query plan. Plan nodes are returned in pre-order starting
    /// with the plan root. Each \[PlanNode\]\[google.spanner.v1.PlanNode\]'s `id` corresponds to its index in
    /// `plan_nodes`.
    #[prost(message, repeated, tag = "1")]
    pub plan_nodes: ::prost::alloc::vec::Vec<PlanNode>,
}
/// `Type` indicates the type of a Cloud Spanner value, as might be stored in a
/// table cell or returned from an SQL query.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Type {
    /// Required. The \[TypeCode\]\[google.spanner.v1.TypeCode\] for this type.
    #[prost(enumeration = "TypeCode", tag = "1")]
    pub code: i32,
    /// If \[code\]\[google.spanner.v1.Type.code\] ==
    /// \[ARRAY\]\[google.spanner.v1.TypeCode.ARRAY\], then `array_element_type` is the
    /// type of the array elements.
    #[prost(message, optional, boxed, tag = "2")]
    pub array_element_type: ::core::option::Option<::prost::alloc::boxed::Box<Type>>,
    /// If \[code\]\[google.spanner.v1.Type.code\] ==
    /// \[STRUCT\]\[google.spanner.v1.TypeCode.STRUCT\], then `struct_type` provides
    /// type information for the struct's fields.
    #[prost(message, optional, tag = "3")]
    pub struct_type: ::core::option::Option<StructType>,
    /// The \[TypeAnnotationCode\]\[google.spanner.v1.TypeAnnotationCode\] that
    /// disambiguates SQL type that Spanner will use to represent values of this
    /// type during query processing. This is necessary for some type codes because
    /// a single \[TypeCode\]\[google.spanner.v1.TypeCode\] can be mapped to different
    /// SQL types depending on the SQL dialect.
    /// \[type_annotation\]\[google.spanner.v1.Type.type_annotation\] typically is not
    /// needed to process the content of a value (it doesn't affect serialization)
    /// and clients can ignore it on the read path.
    #[prost(enumeration = "TypeAnnotationCode", tag = "4")]
    pub type_annotation: i32,
    /// If \[code\]\[google.spanner.v1.Type.code\] ==
    /// \[PROTO\]\[google.spanner.v1.TypeCode.PROTO\] or
    /// \[code\]\[google.spanner.v1.Type.code\] ==
    /// \[ENUM\]\[google.spanner.v1.TypeCode.ENUM\], then `proto_type_fqn` is the fully
    /// qualified name of the proto type representing the proto/enum definition.
    #[prost(string, tag = "5")]
    pub proto_type_fqn: ::prost::alloc::string::String,
}
/// `StructType` defines the fields of a
/// \[STRUCT\]\[google.spanner.v1.TypeCode.STRUCT\] type.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StructType {
    /// The list of fields that make up this struct. Order is
    /// significant, because values of this struct type are represented as
    /// lists, where the order of field values matches the order of
    /// fields in the \[StructType\]\[google.spanner.v1.StructType\]. In turn, the
    /// order of fields matches the order of columns in a read request, or the
    /// order of fields in the `SELECT` clause of a query.
    #[prost(message, repeated, tag = "1")]
    pub fields: ::prost::alloc::vec::Vec<struct_type::Field>,
}
/// Nested message and enum types in `StructType`.
pub mod struct_type {
    /// Message representing a single field of a struct.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Field {
        /// The name of the field. For reads, this is the column name. For
        /// SQL queries, it is the column alias (e.g., `"Word"` in the
        /// query `"SELECT 'hello' AS Word"`), or the column name (e.g.,
        /// `"ColName"` in the query `"SELECT ColName FROM Table"`). Some
        /// columns might have an empty name (e.g., `"SELECT  UPPER(ColName)"`). Note that a query result can contain
        /// multiple fields with the same name.
        #[prost(string, tag = "1")]
        pub name: ::prost::alloc::string::String,
        /// The type of the field.
        #[prost(message, optional, tag = "2")]
        pub r#type: ::core::option::Option<super::Type>,
    }
}
/// `TypeCode` is used as part of \[Type\]\[google.spanner.v1.Type\] to
/// indicate the type of a Cloud Spanner value.
///
/// Each legal value of a type can be encoded to or decoded from a JSON
/// value, using the encodings described below. All Cloud Spanner values can
/// be `null`, regardless of type; `null`s are always encoded as a JSON
/// `null`.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum TypeCode {
    /// Not specified.
    Unspecified = 0,
    /// Encoded as JSON `true` or `false`.
    Bool = 1,
    /// Encoded as `string`, in decimal format.
    Int64 = 2,
    /// Encoded as `number`, or the strings `"NaN"`, `"Infinity"`, or
    /// `"-Infinity"`.
    Float64 = 3,
    /// Encoded as `number`, or the strings `"NaN"`, `"Infinity"`, or
    /// `"-Infinity"`.
    Float32 = 15,
    /// Encoded as `string` in RFC 3339 timestamp format. The time zone
    /// must be present, and must be `"Z"`.
    ///
    /// If the schema has the column option
    /// `allow_commit_timestamp=true`, the placeholder string
    /// `"spanner.commit_timestamp()"` can be used to instruct the system
    /// to insert the commit timestamp associated with the transaction
    /// commit.
    Timestamp = 4,
    /// Encoded as `string` in RFC 3339 date format.
    Date = 5,
    /// Encoded as `string`.
    String = 6,
    /// Encoded as a base64-encoded `string`, as described in RFC 4648,
    /// section 4.
    Bytes = 7,
    /// Encoded as `list`, where the list elements are represented
    /// according to
    /// \[array_element_type\]\[google.spanner.v1.Type.array_element_type\].
    Array = 8,
    /// Encoded as `list`, where list element `i` is represented according
    /// to \[struct_type.fields\[i\]\]\[google.spanner.v1.StructType.fields\].
    Struct = 9,
    /// Encoded as `string`, in decimal format or scientific notation format.
    /// Decimal format:
    /// `\[+-\]Digits\[.[Digits]\]` or
    /// `[+-][Digits].Digits`
    ///
    /// Scientific notation:
    /// `\[+-\]Digits\[.[Digits\]][ExponentIndicator\[+-\]Digits]` or
    /// `[+-][Digits].Digits\[ExponentIndicator[+-\]Digits]`
    /// (ExponentIndicator is `"e"` or `"E"`)
    Numeric = 10,
    /// Encoded as a JSON-formatted `string` as described in RFC 7159. The
    /// following rules are applied when parsing JSON input:
    ///
    /// * Whitespace characters are not preserved.
    /// * If a JSON object has duplicate keys, only the first key is preserved.
    /// * Members of a JSON object are not guaranteed to have their order
    ///   preserved.
    /// * JSON array elements will have their order preserved.
    Json = 11,
    /// Encoded as a base64-encoded `string`, as described in RFC 4648,
    /// section 4.
    Proto = 13,
    /// Encoded as `string`, in decimal format.
    Enum = 14,
    /// Encoded as `string`, in `ISO8601` duration format -
    /// `P\[n\]Y[n]M\[n\]DT\[n\]H[n]M\[n[.fraction]\]S`
    /// where `n` is an integer.
    /// For example, `P1Y2M3DT4H5M6.5S` represents time duration of 1 year, 2
    /// months, 3 days, 4 hours, 5 minutes, and 6.5 seconds.
    Interval = 16,
    /// Encoded as `string`, in lower-case hexa-decimal format, as described
    /// in RFC 9562, section 4.
    Uuid = 17,
}
impl TypeCode {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TYPE_CODE_UNSPECIFIED",
            Self::Bool => "BOOL",
            Self::Int64 => "INT64",
            Self::Float64 => "FLOAT64",
            Self::Float32 => "FLOAT32",
            Self::Timestamp => "TIMESTAMP",
            Self::Date => "DATE",
            Self::String => "STRING",
            Self::Bytes => "BYTES",
            Self::Array => "ARRAY",
            Self::Struct => "STRUCT",
            Self::Numeric => "NUMERIC",
            Self::Json => "JSON",
            Self::Proto => "PROTO",
            Self::Enum => "ENUM",
            Self::Interval => "INTERVAL",
            Self::Uuid => "UUID",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TYPE_CODE_UNSPECIFIED" => Some(Self::Unspecified),
            "BOOL" => Some(Self::Bool),
            "INT64" => Some(Self::Int64),
            "FLOAT64" => Some(Self::Float64),
            "FLOAT32" => Some(Self::Float32),
            "TIMESTAMP" => Some(Self::Timestamp),
            "DATE" => Some(Self::Date),
            "STRING" => Some(Self::String),
            "BYTES" => Some(Self::Bytes),
            "ARRAY" => Some(Self::Array),
            "STRUCT" => Some(Self::Struct),
            "NUMERIC" => Some(Self::Numeric),
            "JSON" => Some(Self::Json),
            "PROTO" => Some(Self::Proto),
            "ENUM" => Some(Self::Enum),
            "INTERVAL" => Some(Self::Interval),
            "UUID" => Some(Self::Uuid),
            _ => None,
        }
    }
}
/// `TypeAnnotationCode` is used as a part of \[Type\]\[google.spanner.v1.Type\] to
/// disambiguate SQL types that should be used for a given Cloud Spanner value.
/// Disambiguation is needed because the same Cloud Spanner type can be mapped to
/// different SQL types depending on SQL dialect. TypeAnnotationCode doesn't
/// affect the way value is serialized.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum TypeAnnotationCode {
    /// Not specified.
    Unspecified = 0,
    /// PostgreSQL compatible NUMERIC type. This annotation needs to be applied to
    /// \[Type\]\[google.spanner.v1.Type\] instances having
    /// \[NUMERIC\]\[google.spanner.v1.TypeCode.NUMERIC\] type code to specify that
    /// values of this type should be treated as PostgreSQL NUMERIC values.
    /// Currently this annotation is always needed for
    /// \[NUMERIC\]\[google.spanner.v1.TypeCode.NUMERIC\] when a client interacts with
    /// PostgreSQL-enabled Spanner databases.
    PgNumeric = 2,
    /// PostgreSQL compatible JSONB type. This annotation needs to be applied to
    /// \[Type\]\[google.spanner.v1.Type\] instances having
    /// \[JSON\]\[google.spanner.v1.TypeCode.JSON\] type code to specify that values of
    /// this type should be treated as PostgreSQL JSONB values. Currently this
    /// annotation is always needed for \[JSON\]\[google.spanner.v1.TypeCode.JSON\]
    /// when a client interacts with PostgreSQL-enabled Spanner databases.
    PgJsonb = 3,
    /// PostgreSQL compatible OID type. This annotation can be used by a client
    /// interacting with PostgreSQL-enabled Spanner database to specify that a
    /// value should be treated using the semantics of the OID type.
    PgOid = 4,
}
impl TypeAnnotationCode {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TYPE_ANNOTATION_CODE_UNSPECIFIED",
            Self::PgNumeric => "PG_NUMERIC",
            Self::PgJsonb => "PG_JSONB",
            Self::PgOid => "PG_OID",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TYPE_ANNOTATION_CODE_UNSPECIFIED" => Some(Self::Unspecified),
            "PG_NUMERIC" => Some(Self::PgNumeric),
            "PG_JSONB" => Some(Self::PgJsonb),
            "PG_OID" => Some(Self::PgOid),
            _ => None,
        }
    }
}
/// Results from \[Read\]\[google.spanner.v1.Spanner.Read\] or
/// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ResultSet {
    /// Metadata about the result set, such as row type information.
    #[prost(message, optional, tag = "1")]
    pub metadata: ::core::option::Option<ResultSetMetadata>,
    /// Each element in `rows` is a row whose format is defined by
    /// \[metadata.row_type\]\[google.spanner.v1.ResultSetMetadata.row_type\]. The ith
    /// element in each row matches the ith field in
    /// \[metadata.row_type\]\[google.spanner.v1.ResultSetMetadata.row_type\]. Elements
    /// are encoded based on type as described \[here\]\[google.spanner.v1.TypeCode\].
    #[prost(message, repeated, tag = "2")]
    pub rows: ::prost::alloc::vec::Vec<::prost_types::ListValue>,
    /// Query plan and execution statistics for the SQL statement that
    /// produced this result set. These can be requested by setting
    /// \[ExecuteSqlRequest.query_mode\]\[google.spanner.v1.ExecuteSqlRequest.query_mode\].
    /// DML statements always produce stats containing the number of rows
    /// modified, unless executed using the
    /// \[ExecuteSqlRequest.QueryMode.PLAN\]\[google.spanner.v1.ExecuteSqlRequest.QueryMode.PLAN\]
    /// \[ExecuteSqlRequest.query_mode\]\[google.spanner.v1.ExecuteSqlRequest.query_mode\].
    /// Other fields might or might not be populated, based on the
    /// \[ExecuteSqlRequest.query_mode\]\[google.spanner.v1.ExecuteSqlRequest.query_mode\].
    #[prost(message, optional, tag = "3")]
    pub stats: ::core::option::Option<ResultSetStats>,
    /// Optional. A precommit token is included if the read-write transaction is on
    /// a multiplexed session. Pass the precommit token with the highest sequence
    /// number from this transaction attempt to the
    /// \[Commit\]\[google.spanner.v1.Spanner.Commit\] request for this transaction.
    #[prost(message, optional, tag = "5")]
    pub precommit_token: ::core::option::Option<MultiplexedSessionPrecommitToken>,
}
/// Partial results from a streaming read or SQL query. Streaming reads and
/// SQL queries better tolerate large result sets, large rows, and large
/// values, but are a little trickier to consume.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PartialResultSet {
    /// Metadata about the result set, such as row type information.
    /// Only present in the first response.
    #[prost(message, optional, tag = "1")]
    pub metadata: ::core::option::Option<ResultSetMetadata>,
    /// A streamed result set consists of a stream of values, which might
    /// be split into many `PartialResultSet` messages to accommodate
    /// large rows and/or large values. Every N complete values defines a
    /// row, where N is equal to the number of entries in
    /// \[metadata.row_type.fields\]\[google.spanner.v1.StructType.fields\].
    ///
    /// Most values are encoded based on type as described
    /// \[here\]\[google.spanner.v1.TypeCode\].
    ///
    /// It's possible that the last value in values is "chunked",
    /// meaning that the rest of the value is sent in subsequent
    /// `PartialResultSet`(s). This is denoted by the
    /// \[chunked_value\]\[google.spanner.v1.PartialResultSet.chunked_value\] field.
    /// Two or more chunked values can be merged to form a complete value as
    /// follows:
    ///
    /// * `bool/number/null`: can't be chunked
    /// * `string`: concatenate the strings
    /// * `list`: concatenate the lists. If the last element in a list is a
    ///   `string`, `list`, or `object`, merge it with the first element in
    ///   the next list by applying these rules recursively.
    /// * `object`: concatenate the (field name, field value) pairs. If a
    ///   field name is duplicated, then apply these rules recursively
    ///   to merge the field values.
    ///
    /// Some examples of merging:
    ///
    /// ```text
    /// Strings are concatenated.
    /// "foo", "bar" => "foobar"
    ///
    /// Lists of non-strings are concatenated.
    /// \[2, 3\], \[4\] => \[2, 3, 4\]
    ///
    /// Lists are concatenated, but the last and first elements are merged
    /// because they are strings.
    /// \["a", "b"\], \["c", "d"\] => \["a", "bc", "d"\]
    ///
    /// Lists are concatenated, but the last and first elements are merged
    /// because they are lists. Recursively, the last and first elements
    /// of the inner lists are merged because they are strings.
    /// \["a", ["b", "c"]\], \[["d"\], "e"] => \["a", ["b", "cd"\], "e"]
    ///
    /// Non-overlapping object fields are combined.
    /// {"a": "1"}, {"b": "2"} => {"a": "1", "b": 2"}
    ///
    /// Overlapping object fields are merged.
    /// {"a": "1"}, {"a": "2"} => {"a": "12"}
    ///
    /// Examples of merging objects containing lists of strings.
    /// {"a": \["1"\]}, {"a": \["2"\]} => {"a": \["12"\]}
    /// ```
    ///
    /// For a more complete example, suppose a streaming SQL query is
    /// yielding a result set whose rows contain a single string
    /// field. The following `PartialResultSet`s might be yielded:
    ///
    /// ```text
    /// {
    ///    "metadata": { ... }
    ///    "values": \["Hello", "W"\]
    ///    "chunked_value": true
    ///    "resume_token": "Af65..."
    /// }
    /// {
    ///    "values": \["orl"\]
    ///    "chunked_value": true
    /// }
    /// {
    ///    "values": \["d"\]
    ///    "resume_token": "Zx1B..."
    /// }
    /// ```
    ///
    /// This sequence of `PartialResultSet`s encodes two rows, one
    /// containing the field value `"Hello"`, and a second containing the
    /// field value `"World" = "W" + "orl" + "d"`.
    ///
    /// Not all `PartialResultSet`s contain a `resume_token`. Execution can only be
    /// resumed from a previously yielded `resume_token`. For the above sequence of
    /// `PartialResultSet`s, resuming the query with `"resume_token": "Af65..."`
    /// yields results from the `PartialResultSet` with value "orl".
    #[prost(message, repeated, tag = "2")]
    pub values: ::prost::alloc::vec::Vec<::prost_types::Value>,
    /// If true, then the final value in
    /// \[values\]\[google.spanner.v1.PartialResultSet.values\] is chunked, and must be
    /// combined with more values from subsequent `PartialResultSet`s to obtain a
    /// complete field value.
    #[prost(bool, tag = "3")]
    pub chunked_value: bool,
    /// Streaming calls might be interrupted for a variety of reasons, such
    /// as TCP connection loss. If this occurs, the stream of results can
    /// be resumed by re-sending the original request and including
    /// `resume_token`. Note that executing any other transaction in the
    /// same session invalidates the token.
    #[prost(bytes = "vec", tag = "4")]
    pub resume_token: ::prost::alloc::vec::Vec<u8>,
    /// Query plan and execution statistics for the statement that produced this
    /// streaming result set. These can be requested by setting
    /// \[ExecuteSqlRequest.query_mode\]\[google.spanner.v1.ExecuteSqlRequest.query_mode\]
    /// and are sent only once with the last response in the stream. This field is
    /// also present in the last response for DML statements.
    #[prost(message, optional, tag = "5")]
    pub stats: ::core::option::Option<ResultSetStats>,
    /// Optional. A precommit token is included if the read-write transaction
    /// has multiplexed sessions enabled. Pass the precommit token with the highest
    /// sequence number from this transaction attempt to the
    /// \[Commit\]\[google.spanner.v1.Spanner.Commit\] request for this transaction.
    #[prost(message, optional, tag = "8")]
    pub precommit_token: ::core::option::Option<MultiplexedSessionPrecommitToken>,
    /// Optional. Indicates whether this is the last `PartialResultSet` in the
    /// stream. The server might optionally set this field. Clients shouldn't rely
    /// on this field being set in all cases.
    #[prost(bool, tag = "9")]
    pub last: bool,
}
/// Metadata about a \[ResultSet\]\[google.spanner.v1.ResultSet\] or
/// \[PartialResultSet\]\[google.spanner.v1.PartialResultSet\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ResultSetMetadata {
    /// Indicates the field names and types for the rows in the result
    /// set. For example, a SQL query like `"SELECT UserId, UserName FROM  Users"` could return a `row_type` value like:
    ///
    /// ```text
    /// "fields": [
    ///    { "name": "UserId", "type": { "code": "INT64" } },
    ///    { "name": "UserName", "type": { "code": "STRING" } },
    /// ]
    /// ```
    #[prost(message, optional, tag = "1")]
    pub row_type: ::core::option::Option<StructType>,
    /// If the read or SQL query began a transaction as a side-effect, the
    /// information about the new transaction is yielded here.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<Transaction>,
    /// A SQL query can be parameterized. In PLAN mode, these parameters can be
    /// undeclared. This indicates the field names and types for those undeclared
    /// parameters in the SQL query. For example, a SQL query like `"SELECT * FROM  Users where UserId = @userId and UserName = @userName "` could return a
    /// `undeclared_parameters` value like:
    ///
    /// ```text
    /// "fields": [
    ///    { "name": "UserId", "type": { "code": "INT64" } },
    ///    { "name": "UserName", "type": { "code": "STRING" } },
    /// ]
    /// ```
    #[prost(message, optional, tag = "3")]
    pub undeclared_parameters: ::core::option::Option<StructType>,
}
/// Additional statistics about a \[ResultSet\]\[google.spanner.v1.ResultSet\] or
/// \[PartialResultSet\]\[google.spanner.v1.PartialResultSet\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ResultSetStats {
    /// \[QueryPlan\]\[google.spanner.v1.QueryPlan\] for the query associated with this
    /// result.
    #[prost(message, optional, tag = "1")]
    pub query_plan: ::core::option::Option<QueryPlan>,
    /// Aggregated statistics from the execution of the query. Only present when
    /// the query is profiled. For example, a query could return the statistics as
    /// follows:
    ///
    /// ```text
    /// {
    ///    "rows_returned": "3",
    ///    "elapsed_time": "1.22 secs",
    ///    "cpu_time": "1.19 secs"
    /// }
    /// ```
    #[prost(message, optional, tag = "2")]
    pub query_stats: ::core::option::Option<::prost_types::Struct>,
    /// The number of rows modified by the DML statement.
    #[prost(oneof = "result_set_stats::RowCount", tags = "3, 4")]
    pub row_count: ::core::option::Option<result_set_stats::RowCount>,
}
/// Nested message and enum types in `ResultSetStats`.
pub mod result_set_stats {
    /// The number of rows modified by the DML statement.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum RowCount {
        /// Standard DML returns an exact count of rows that were modified.
        #[prost(int64, tag = "3")]
        RowCountExact(i64),
        /// Partitioned DML doesn't offer exactly-once semantics, so it
        /// returns a lower bound of the rows modified.
        #[prost(int64, tag = "4")]
        RowCountLowerBound(i64),
    }
}
/// The request for \[CreateSession\]\[google.spanner.v1.Spanner.CreateSession\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateSessionRequest {
    /// Required. The database in which the new session is created.
    #[prost(string, tag = "1")]
    pub database: ::prost::alloc::string::String,
    /// Required. The session to create.
    #[prost(message, optional, tag = "2")]
    pub session: ::core::option::Option<Session>,
}
/// The request for
/// \[BatchCreateSessions\]\[google.spanner.v1.Spanner.BatchCreateSessions\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BatchCreateSessionsRequest {
    /// Required. The database in which the new sessions are created.
    #[prost(string, tag = "1")]
    pub database: ::prost::alloc::string::String,
    /// Parameters to be applied to each created session.
    #[prost(message, optional, tag = "2")]
    pub session_template: ::core::option::Option<Session>,
    /// Required. The number of sessions to be created in this batch call.
    /// The API may return fewer than the requested number of sessions. If a
    /// specific number of sessions are desired, the client can make additional
    /// calls to BatchCreateSessions (adjusting
    /// \[session_count\]\[google.spanner.v1.BatchCreateSessionsRequest.session_count\]
    /// as necessary).
    #[prost(int32, tag = "3")]
    pub session_count: i32,
}
/// The response for
/// \[BatchCreateSessions\]\[google.spanner.v1.Spanner.BatchCreateSessions\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BatchCreateSessionsResponse {
    /// The freshly created sessions.
    #[prost(message, repeated, tag = "1")]
    pub session: ::prost::alloc::vec::Vec<Session>,
}
/// A session in the Cloud Spanner API.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Session {
    /// Output only. The name of the session. This is always system-assigned.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The labels for the session.
    ///
    /// * Label keys must be between 1 and 63 characters long and must conform to
    ///   the following regular expression: `[a-z](\[-a-z0-9\]*[a-z0-9])?`.
    /// * Label values must be between 0 and 63 characters long and must conform
    ///   to the regular expression `([a-z](\[-a-z0-9\]*[a-z0-9])?)?`.
    /// * No more than 64 labels can be associated with a given session.
    ///
    /// See <https://goo.gl/xmQnxf> for more information on and examples of labels.
    #[prost(map = "string, string", tag = "2")]
    pub labels: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Output only. The timestamp when the session is created.
    #[prost(message, optional, tag = "3")]
    pub create_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. The approximate timestamp when the session is last used. It is
    /// typically earlier than the actual last use time.
    #[prost(message, optional, tag = "4")]
    pub approximate_last_use_time: ::core::option::Option<::prost_types::Timestamp>,
    /// The database role which created this session.
    #[prost(string, tag = "5")]
    pub creator_role: ::prost::alloc::string::String,
    /// Optional. If true, specifies a multiplexed session. A multiplexed session
    /// may be used for multiple, concurrent read-only operations but can not be
    /// used for read-write transactions, partitioned reads, or partitioned
    /// queries. Multiplexed sessions can be created via
    /// \[CreateSession\]\[google.spanner.v1.Spanner.CreateSession\] but not via
    /// \[BatchCreateSessions\]\[google.spanner.v1.Spanner.BatchCreateSessions\].
    /// Multiplexed sessions may not be deleted nor listed.
    #[prost(bool, tag = "6")]
    pub multiplexed: bool,
}
/// The request for \[GetSession\]\[google.spanner.v1.Spanner.GetSession\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GetSessionRequest {
    /// Required. The name of the session to retrieve.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// The request for \[ListSessions\]\[google.spanner.v1.Spanner.ListSessions\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ListSessionsRequest {
    /// Required. The database in which to list sessions.
    #[prost(string, tag = "1")]
    pub database: ::prost::alloc::string::String,
    /// Number of sessions to be returned in the response. If 0 or less, defaults
    /// to the server's maximum allowed page size.
    #[prost(int32, tag = "2")]
    pub page_size: i32,
    /// If non-empty, `page_token` should contain a
    /// \[next_page_token\]\[google.spanner.v1.ListSessionsResponse.next_page_token\]
    /// from a previous
    /// \[ListSessionsResponse\]\[google.spanner.v1.ListSessionsResponse\].
    #[prost(string, tag = "3")]
    pub page_token: ::prost::alloc::string::String,
    /// An expression for filtering the results of the request. Filter rules are
    /// case insensitive. The fields eligible for filtering are:
    ///
    /// * `labels.key` where key is the name of a label
    ///
    /// Some examples of using filters are:
    ///
    /// * `labels.env:*` --> The session has the label "env".
    /// * `labels.env:dev` --> The session has the label "env" and the value of
    ///   the label contains the string "dev".
    #[prost(string, tag = "4")]
    pub filter: ::prost::alloc::string::String,
}
/// The response for \[ListSessions\]\[google.spanner.v1.Spanner.ListSessions\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListSessionsResponse {
    /// The list of requested sessions.
    #[prost(message, repeated, tag = "1")]
    pub sessions: ::prost::alloc::vec::Vec<Session>,
    /// `next_page_token` can be sent in a subsequent
    /// \[ListSessions\]\[google.spanner.v1.Spanner.ListSessions\] call to fetch more
    /// of the matching sessions.
    #[prost(string, tag = "2")]
    pub next_page_token: ::prost::alloc::string::String,
}
/// The request for \[DeleteSession\]\[google.spanner.v1.Spanner.DeleteSession\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DeleteSessionRequest {
    /// Required. The name of the session to delete.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// Common request options for various APIs.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RequestOptions {
    /// Priority for the request.
    #[prost(enumeration = "request_options::Priority", tag = "1")]
    pub priority: i32,
    /// A per-request tag which can be applied to queries or reads, used for
    /// statistics collection.
    /// Both request_tag and transaction_tag can be specified for a read or query
    /// that belongs to a transaction.
    /// This field is ignored for requests where it's not applicable (e.g.
    /// CommitRequest).
    /// Legal characters for `request_tag` values are all printable characters
    /// (ASCII 32 - 126) and the length of a request_tag is limited to 50
    /// characters. Values that exceed this limit are truncated.
    /// Any leading underscore (\_) characters will be removed from the string.
    #[prost(string, tag = "2")]
    pub request_tag: ::prost::alloc::string::String,
    /// A tag used for statistics collection about this transaction.
    /// Both request_tag and transaction_tag can be specified for a read or query
    /// that belongs to a transaction.
    /// The value of transaction_tag should be the same for all requests belonging
    /// to the same transaction.
    /// If this request doesn't belong to any transaction, transaction_tag will be
    /// ignored.
    /// Legal characters for `transaction_tag` values are all printable characters
    /// (ASCII 32 - 126) and the length of a transaction_tag is limited to 50
    /// characters. Values that exceed this limit are truncated.
    /// Any leading underscore (\_) characters will be removed from the string.
    #[prost(string, tag = "3")]
    pub transaction_tag: ::prost::alloc::string::String,
}
/// Nested message and enum types in `RequestOptions`.
pub mod request_options {
    /// The relative priority for requests. Note that priority is not applicable
    /// for \[BeginTransaction\]\[google.spanner.v1.Spanner.BeginTransaction\].
    ///
    /// The priority acts as a hint to the Cloud Spanner scheduler and does not
    /// guarantee priority or order of execution. For example:
    ///
    /// * Some parts of a write operation always execute at `PRIORITY_HIGH`,
    ///   regardless of the specified priority. This may cause you to see an
    ///   increase in high priority workload even when executing a low priority
    ///   request. This can also potentially cause a priority inversion where a
    ///   lower priority request will be fulfilled ahead of a higher priority
    ///   request.
    /// * If a transaction contains multiple operations with different priorities,
    ///   Cloud Spanner does not guarantee to process the higher priority
    ///   operations first. There may be other constraints to satisfy, such as
    ///   order of operations.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Priority {
        /// `PRIORITY_UNSPECIFIED` is equivalent to `PRIORITY_HIGH`.
        Unspecified = 0,
        /// This specifies that the request is low priority.
        Low = 1,
        /// This specifies that the request is medium priority.
        Medium = 2,
        /// This specifies that the request is high priority.
        High = 3,
    }
    impl Priority {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "PRIORITY_UNSPECIFIED",
                Self::Low => "PRIORITY_LOW",
                Self::Medium => "PRIORITY_MEDIUM",
                Self::High => "PRIORITY_HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PRIORITY_UNSPECIFIED" => Some(Self::Unspecified),
                "PRIORITY_LOW" => Some(Self::Low),
                "PRIORITY_MEDIUM" => Some(Self::Medium),
                "PRIORITY_HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
}
/// The DirectedReadOptions can be used to indicate which replicas or regions
/// should be used for non-transactional reads or queries.
///
/// DirectedReadOptions may only be specified for a read-only transaction,
/// otherwise the API will return an `INVALID_ARGUMENT` error.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectedReadOptions {
    /// Required. At most one of either include_replicas or exclude_replicas
    /// should be present in the message.
    #[prost(oneof = "directed_read_options::Replicas", tags = "1, 2")]
    pub replicas: ::core::option::Option<directed_read_options::Replicas>,
}
/// Nested message and enum types in `DirectedReadOptions`.
pub mod directed_read_options {
    /// The directed read replica selector.
    /// Callers must provide one or more of the following fields for replica
    /// selection:
    ///
    /// * `location` - The location must be one of the regions within the
    ///   multi-region configuration of your database.
    /// * `type` - The type of the replica.
    ///
    /// Some examples of using replica_selectors are:
    ///
    /// * `location:us-east1` --> The "us-east1" replica(s) of any available type
    ///   will be used to process the request.
    /// * `type:READ_ONLY`    --> The "READ_ONLY" type replica(s) in nearest
    ///   available location will be used to process the
    ///   request.
    /// * `location:us-east1 type:READ_ONLY` --> The "READ_ONLY" type replica(s)
    ///   in location "us-east1" will be used to process
    ///   the request.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ReplicaSelection {
        /// The location or region of the serving requests, e.g. "us-east1".
        #[prost(string, tag = "1")]
        pub location: ::prost::alloc::string::String,
        /// The type of replica.
        #[prost(enumeration = "replica_selection::Type", tag = "2")]
        pub r#type: i32,
    }
    /// Nested message and enum types in `ReplicaSelection`.
    pub mod replica_selection {
        /// Indicates the type of replica.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum Type {
            /// Not specified.
            Unspecified = 0,
            /// Read-write replicas support both reads and writes.
            ReadWrite = 1,
            /// Read-only replicas only support reads (not writes).
            ReadOnly = 2,
        }
        impl Type {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "TYPE_UNSPECIFIED",
                    Self::ReadWrite => "READ_WRITE",
                    Self::ReadOnly => "READ_ONLY",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                    "READ_WRITE" => Some(Self::ReadWrite),
                    "READ_ONLY" => Some(Self::ReadOnly),
                    _ => None,
                }
            }
        }
    }
    /// An IncludeReplicas contains a repeated set of ReplicaSelection which
    /// indicates the order in which replicas should be considered.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct IncludeReplicas {
        /// The directed read replica selector.
        #[prost(message, repeated, tag = "1")]
        pub replica_selections: ::prost::alloc::vec::Vec<ReplicaSelection>,
        /// If true, Spanner will not route requests to a replica outside the
        /// include_replicas list when all of the specified replicas are unavailable
        /// or unhealthy. Default value is `false`.
        #[prost(bool, tag = "2")]
        pub auto_failover_disabled: bool,
    }
    /// An ExcludeReplicas contains a repeated set of ReplicaSelection that should
    /// be excluded from serving requests.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct ExcludeReplicas {
        /// The directed read replica selector.
        #[prost(message, repeated, tag = "1")]
        pub replica_selections: ::prost::alloc::vec::Vec<ReplicaSelection>,
    }
    /// Required. At most one of either include_replicas or exclude_replicas
    /// should be present in the message.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Replicas {
        /// Include_replicas indicates the order of replicas (as they appear in
        /// this list) to process the request. If auto_failover_disabled is set to
        /// true and all replicas are exhausted without finding a healthy replica,
        /// Spanner will wait for a replica in the list to become available, requests
        /// may fail due to `DEADLINE_EXCEEDED` errors.
        #[prost(message, tag = "1")]
        IncludeReplicas(IncludeReplicas),
        /// Exclude_replicas indicates that specified replicas should be excluded
        /// from serving requests. Spanner will not route requests to the replicas
        /// in this list.
        #[prost(message, tag = "2")]
        ExcludeReplicas(ExcludeReplicas),
    }
}
/// The request for \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\] and
/// \[ExecuteStreamingSql\]\[google.spanner.v1.Spanner.ExecuteStreamingSql\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteSqlRequest {
    /// Required. The session in which the SQL query should be performed.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// The transaction to use.
    ///
    /// For queries, if none is provided, the default is a temporary read-only
    /// transaction with strong concurrency.
    ///
    /// Standard DML statements require a read-write transaction. To protect
    /// against replays, single-use transactions are not supported.  The caller
    /// must either supply an existing transaction ID or begin a new transaction.
    ///
    /// Partitioned DML requires an existing Partitioned DML transaction ID.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<TransactionSelector>,
    /// Required. The SQL string.
    #[prost(string, tag = "3")]
    pub sql: ::prost::alloc::string::String,
    /// Parameter names and values that bind to placeholders in the SQL string.
    ///
    /// A parameter placeholder consists of the `@` character followed by the
    /// parameter name (for example, `@firstName`). Parameter names must conform
    /// to the naming requirements of identifiers as specified at
    /// <https://cloud.google.com/spanner/docs/lexical#identifiers.>
    ///
    /// Parameters can appear anywhere that a literal value is expected.  The same
    /// parameter name can be used more than once, for example:
    ///
    /// `"WHERE id > @msg_id AND id < @msg_id + 100"`
    ///
    /// It is an error to execute a SQL statement with unbound parameters.
    #[prost(message, optional, tag = "4")]
    pub params: ::core::option::Option<::prost_types::Struct>,
    /// It is not always possible for Cloud Spanner to infer the right SQL type
    /// from a JSON value.  For example, values of type `BYTES` and values
    /// of type `STRING` both appear in
    /// \[params\]\[google.spanner.v1.ExecuteSqlRequest.params\] as JSON strings.
    ///
    /// In these cases, `param_types` can be used to specify the exact
    /// SQL type for some or all of the SQL statement parameters. See the
    /// definition of \[Type\]\[google.spanner.v1.Type\] for more information
    /// about SQL types.
    #[prost(map = "string, message", tag = "5")]
    pub param_types: ::std::collections::HashMap<::prost::alloc::string::String, Type>,
    /// If this request is resuming a previously interrupted SQL statement
    /// execution, `resume_token` should be copied from the last
    /// \[PartialResultSet\]\[google.spanner.v1.PartialResultSet\] yielded before the
    /// interruption. Doing this enables the new SQL statement execution to resume
    /// where the last one left off. The rest of the request parameters must
    /// exactly match the request that yielded this token.
    #[prost(bytes = "vec", tag = "6")]
    pub resume_token: ::prost::alloc::vec::Vec<u8>,
    /// Used to control the amount of debugging information returned in
    /// \[ResultSetStats\]\[google.spanner.v1.ResultSetStats\]. If
    /// \[partition_token\]\[google.spanner.v1.ExecuteSqlRequest.partition_token\] is
    /// set, \[query_mode\]\[google.spanner.v1.ExecuteSqlRequest.query_mode\] can only
    /// be set to
    /// \[QueryMode.NORMAL\]\[google.spanner.v1.ExecuteSqlRequest.QueryMode.NORMAL\].
    #[prost(enumeration = "execute_sql_request::QueryMode", tag = "7")]
    pub query_mode: i32,
    /// If present, results will be restricted to the specified partition
    /// previously created using PartitionQuery().  There must be an exact
    /// match for the values of fields common to this message and the
    /// PartitionQueryRequest message used to create this partition_token.
    #[prost(bytes = "vec", tag = "8")]
    pub partition_token: ::prost::alloc::vec::Vec<u8>,
    /// A per-transaction sequence number used to identify this request. This field
    /// makes each request idempotent such that if the request is received multiple
    /// times, at most one will succeed.
    ///
    /// The sequence number must be monotonically increasing within the
    /// transaction. If a request arrives for the first time with an out-of-order
    /// sequence number, the transaction may be aborted. Replays of previously
    /// handled requests will yield the same response as the first execution.
    ///
    /// Required for DML statements. Ignored for queries.
    #[prost(int64, tag = "9")]
    pub seqno: i64,
    /// Query optimizer configuration to use for the given query.
    #[prost(message, optional, tag = "10")]
    pub query_options: ::core::option::Option<execute_sql_request::QueryOptions>,
    /// Common options for this request.
    #[prost(message, optional, tag = "11")]
    pub request_options: ::core::option::Option<RequestOptions>,
    /// Directed read options for this request.
    #[prost(message, optional, tag = "15")]
    pub directed_read_options: ::core::option::Option<DirectedReadOptions>,
    /// If this is for a partitioned query and this field is set to `true`, the
    /// request is executed with Spanner Data Boost independent compute resources.
    ///
    /// If the field is set to `true` but the request does not set
    /// `partition_token`, the API returns an `INVALID_ARGUMENT` error.
    #[prost(bool, tag = "16")]
    pub data_boost_enabled: bool,
    /// Optional. If set to true, this statement marks the end of the transaction.
    /// The transaction should be committed or aborted after this statement
    /// executes, and attempts to execute any other requests against this
    /// transaction (including reads and queries) will be rejected.
    ///
    /// For DML statements, setting this option may cause some error reporting to
    /// be deferred until commit time (e.g. validation of unique constraints).
    /// Given this, successful execution of a DML statement should not be assumed
    /// until a subsequent Commit call completes successfully.
    #[prost(bool, tag = "17")]
    pub last_statement: bool,
}
/// Nested message and enum types in `ExecuteSqlRequest`.
pub mod execute_sql_request {
    /// Query optimizer configuration.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct QueryOptions {
        /// An option to control the selection of optimizer version.
        ///
        /// This parameter allows individual queries to pick different query
        /// optimizer versions.
        ///
        /// Specifying `latest` as a value instructs Cloud Spanner to use the
        /// latest supported query optimizer version. If not specified, Cloud Spanner
        /// uses the optimizer version set at the database level options. Any other
        /// positive integer (from the list of supported optimizer versions)
        /// overrides the default optimizer version for query execution.
        ///
        /// The list of supported optimizer versions can be queried from
        /// SPANNER_SYS.SUPPORTED_OPTIMIZER_VERSIONS.
        ///
        /// Executing a SQL statement with an invalid optimizer version fails with
        /// an `INVALID_ARGUMENT` error.
        ///
        /// See
        /// <https://cloud.google.com/spanner/docs/query-optimizer/manage-query-optimizer>
        /// for more information on managing the query optimizer.
        ///
        /// The `optimizer_version` statement hint has precedence over this setting.
        #[prost(string, tag = "1")]
        pub optimizer_version: ::prost::alloc::string::String,
        /// An option to control the selection of optimizer statistics package.
        ///
        /// This parameter allows individual queries to use a different query
        /// optimizer statistics package.
        ///
        /// Specifying `latest` as a value instructs Cloud Spanner to use the latest
        /// generated statistics package. If not specified, Cloud Spanner uses
        /// the statistics package set at the database level options, or the latest
        /// package if the database option is not set.
        ///
        /// The statistics package requested by the query has to be exempt from
        /// garbage collection. This can be achieved with the following DDL
        /// statement:
        ///
        /// ```text,
        /// ALTER STATISTICS <package_name> SET OPTIONS (allow_gc=false)
        /// ```
        ///
        /// The list of available statistics packages can be queried from
        /// `INFORMATION_SCHEMA.SPANNER_STATISTICS`.
        ///
        /// Executing a SQL statement with an invalid optimizer statistics package
        /// or with a statistics package that allows garbage collection fails with
        /// an `INVALID_ARGUMENT` error.
        #[prost(string, tag = "2")]
        pub optimizer_statistics_package: ::prost::alloc::string::String,
    }
    /// Mode in which the statement must be processed.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum QueryMode {
        /// The default mode. Only the statement results are returned.
        Normal = 0,
        /// This mode returns only the query plan, without any results or
        /// execution statistics information.
        Plan = 1,
        /// This mode returns the query plan, overall execution statistics,
        /// operator level execution statistics along with the results. This has a
        /// performance overhead compared to the other modes. It is not recommended
        /// to use this mode for production traffic.
        Profile = 2,
        /// This mode returns the overall (but not operator-level) execution
        /// statistics along with the results.
        WithStats = 3,
        /// This mode returns the query plan, overall (but not operator-level)
        /// execution statistics along with the results.
        WithPlanAndStats = 4,
    }
    impl QueryMode {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Normal => "NORMAL",
                Self::Plan => "PLAN",
                Self::Profile => "PROFILE",
                Self::WithStats => "WITH_STATS",
                Self::WithPlanAndStats => "WITH_PLAN_AND_STATS",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "NORMAL" => Some(Self::Normal),
                "PLAN" => Some(Self::Plan),
                "PROFILE" => Some(Self::Profile),
                "WITH_STATS" => Some(Self::WithStats),
                "WITH_PLAN_AND_STATS" => Some(Self::WithPlanAndStats),
                _ => None,
            }
        }
    }
}
/// The request for \[ExecuteBatchDml\]\[google.spanner.v1.Spanner.ExecuteBatchDml\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteBatchDmlRequest {
    /// Required. The session in which the DML statements should be performed.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// Required. The transaction to use. Must be a read-write transaction.
    ///
    /// To protect against replays, single-use transactions are not supported. The
    /// caller must either supply an existing transaction ID or begin a new
    /// transaction.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<TransactionSelector>,
    /// Required. The list of statements to execute in this batch. Statements are
    /// executed serially, such that the effects of statement `i` are visible to
    /// statement `i+1`. Each statement must be a DML statement. Execution stops at
    /// the first failed statement; the remaining statements are not executed.
    ///
    /// Callers must provide at least one statement.
    #[prost(message, repeated, tag = "3")]
    pub statements: ::prost::alloc::vec::Vec<execute_batch_dml_request::Statement>,
    /// Required. A per-transaction sequence number used to identify this request.
    /// This field makes each request idempotent such that if the request is
    /// received multiple times, at most one will succeed.
    ///
    /// The sequence number must be monotonically increasing within the
    /// transaction. If a request arrives for the first time with an out-of-order
    /// sequence number, the transaction may be aborted. Replays of previously
    /// handled requests will yield the same response as the first execution.
    #[prost(int64, tag = "4")]
    pub seqno: i64,
    /// Common options for this request.
    #[prost(message, optional, tag = "5")]
    pub request_options: ::core::option::Option<RequestOptions>,
    /// Optional. If set to true, this request marks the end of the transaction.
    /// The transaction should be committed or aborted after these statements
    /// execute, and attempts to execute any other requests against this
    /// transaction (including reads and queries) will be rejected.
    ///
    /// Setting this option may cause some error reporting to be deferred until
    /// commit time (e.g. validation of unique constraints). Given this, successful
    /// execution of statements should not be assumed until a subsequent Commit
    /// call completes successfully.
    #[prost(bool, tag = "6")]
    pub last_statements: bool,
}
/// Nested message and enum types in `ExecuteBatchDmlRequest`.
pub mod execute_batch_dml_request {
    /// A single DML statement.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Statement {
        /// Required. The DML string.
        #[prost(string, tag = "1")]
        pub sql: ::prost::alloc::string::String,
        /// Parameter names and values that bind to placeholders in the DML string.
        ///
        /// A parameter placeholder consists of the `@` character followed by the
        /// parameter name (for example, `@firstName`). Parameter names can contain
        /// letters, numbers, and underscores.
        ///
        /// Parameters can appear anywhere that a literal value is expected.  The
        /// same parameter name can be used more than once, for example:
        ///
        /// `"WHERE id > @msg_id AND id < @msg_id + 100"`
        ///
        /// It is an error to execute a SQL statement with unbound parameters.
        #[prost(message, optional, tag = "2")]
        pub params: ::core::option::Option<::prost_types::Struct>,
        /// It is not always possible for Cloud Spanner to infer the right SQL type
        /// from a JSON value.  For example, values of type `BYTES` and values
        /// of type `STRING` both appear in
        /// \[params\]\[google.spanner.v1.ExecuteBatchDmlRequest.Statement.params\] as
        /// JSON strings.
        ///
        /// In these cases, `param_types` can be used to specify the exact
        /// SQL type for some or all of the SQL statement parameters. See the
        /// definition of \[Type\]\[google.spanner.v1.Type\] for more information
        /// about SQL types.
        #[prost(map = "string, message", tag = "3")]
        pub param_types: ::std::collections::HashMap<
            ::prost::alloc::string::String,
            super::Type,
        >,
    }
}
/// The response for
/// \[ExecuteBatchDml\]\[google.spanner.v1.Spanner.ExecuteBatchDml\]. Contains a list
/// of \[ResultSet\]\[google.spanner.v1.ResultSet\] messages, one for each DML
/// statement that has successfully executed, in the same order as the statements
/// in the request. If a statement fails, the status in the response body
/// identifies the cause of the failure.
///
/// To check for DML statements that failed, use the following approach:
///
/// 1. Check the status in the response message. The
///    \[google.rpc.Code\]\[google.rpc.Code\] enum
///    value `OK` indicates that all statements were executed successfully.
/// 1. If the status was not `OK`, check the number of result sets in the
///    response. If the response contains `N`
///    \[ResultSet\]\[google.spanner.v1.ResultSet\] messages, then statement `N+1` in
///    the request failed.
///
/// Example 1:
///
/// * Request: 5 DML statements, all executed successfully.
/// * Response: 5 \[ResultSet\]\[google.spanner.v1.ResultSet\] messages, with the
///   status `OK`.
///
/// Example 2:
///
/// * Request: 5 DML statements. The third statement has a syntax error.
/// * Response: 2 \[ResultSet\]\[google.spanner.v1.ResultSet\] messages, and a syntax
///   error (`INVALID_ARGUMENT`)
///   status. The number of \[ResultSet\]\[google.spanner.v1.ResultSet\] messages
///   indicates that the third statement failed, and the fourth and fifth
///   statements were not executed.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecuteBatchDmlResponse {
    /// One \[ResultSet\]\[google.spanner.v1.ResultSet\] for each statement in the
    /// request that ran successfully, in the same order as the statements in the
    /// request. Each \[ResultSet\]\[google.spanner.v1.ResultSet\] does not contain any
    /// rows. The \[ResultSetStats\]\[google.spanner.v1.ResultSetStats\] in each
    /// \[ResultSet\]\[google.spanner.v1.ResultSet\] contain the number of rows
    /// modified by the statement.
    ///
    /// Only the first \[ResultSet\]\[google.spanner.v1.ResultSet\] in the response
    /// contains valid \[ResultSetMetadata\]\[google.spanner.v1.ResultSetMetadata\].
    #[prost(message, repeated, tag = "1")]
    pub result_sets: ::prost::alloc::vec::Vec<ResultSet>,
    /// If all DML statements are executed successfully, the status is `OK`.
    /// Otherwise, the error status of the first failed statement.
    #[prost(message, optional, tag = "2")]
    pub status: ::core::option::Option<super::super::rpc::Status>,
    /// Optional. A precommit token will be included if the read-write transaction
    /// is on a multiplexed session.
    /// The precommit token with the highest sequence number from this transaction
    /// attempt should be passed to the
    /// \[Commit\]\[google.spanner.v1.Spanner.Commit\] request for this transaction.
    /// This feature is not yet supported and will result in an UNIMPLEMENTED
    /// error.
    #[prost(message, optional, tag = "3")]
    pub precommit_token: ::core::option::Option<MultiplexedSessionPrecommitToken>,
}
/// Options for a PartitionQueryRequest and
/// PartitionReadRequest.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct PartitionOptions {
    /// **Note:** This hint is currently ignored by PartitionQuery and
    /// PartitionRead requests.
    ///
    /// The desired data size for each partition generated.  The default for this
    /// option is currently 1 GiB.  This is only a hint. The actual size of each
    /// partition may be smaller or larger than this size request.
    #[prost(int64, tag = "1")]
    pub partition_size_bytes: i64,
    /// **Note:** This hint is currently ignored by PartitionQuery and
    /// PartitionRead requests.
    ///
    /// The desired maximum number of partitions to return.  For example, this may
    /// be set to the number of workers available.  The default for this option
    /// is currently 10,000. The maximum value is currently 200,000.  This is only
    /// a hint.  The actual number of partitions returned may be smaller or larger
    /// than this maximum count request.
    #[prost(int64, tag = "2")]
    pub max_partitions: i64,
}
/// The request for \[PartitionQuery\]\[google.spanner.v1.Spanner.PartitionQuery\]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PartitionQueryRequest {
    /// Required. The session used to create the partitions.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// Read only snapshot transactions are supported, read/write and single use
    /// transactions are not.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<TransactionSelector>,
    /// Required. The query request to generate partitions for. The request will
    /// fail if the query is not root partitionable. For a query to be root
    /// partitionable, it needs to satisfy a few conditions. For example, if the
    /// query execution plan contains a distributed union operator, then it must be
    /// the first operator in the plan. For more information about other
    /// conditions, see [Read data in
    /// parallel](<https://cloud.google.com/spanner/docs/reads#read_data_in_parallel>).
    ///
    /// The query request must not contain DML commands, such as INSERT, UPDATE, or
    /// DELETE. Use
    /// \[ExecuteStreamingSql\]\[google.spanner.v1.Spanner.ExecuteStreamingSql\] with a
    /// PartitionedDml transaction for large, partition-friendly DML operations.
    #[prost(string, tag = "3")]
    pub sql: ::prost::alloc::string::String,
    /// Parameter names and values that bind to placeholders in the SQL string.
    ///
    /// A parameter placeholder consists of the `@` character followed by the
    /// parameter name (for example, `@firstName`). Parameter names can contain
    /// letters, numbers, and underscores.
    ///
    /// Parameters can appear anywhere that a literal value is expected.  The same
    /// parameter name can be used more than once, for example:
    ///
    /// `"WHERE id > @msg_id AND id < @msg_id + 100"`
    ///
    /// It is an error to execute a SQL statement with unbound parameters.
    #[prost(message, optional, tag = "4")]
    pub params: ::core::option::Option<::prost_types::Struct>,
    /// It is not always possible for Cloud Spanner to infer the right SQL type
    /// from a JSON value.  For example, values of type `BYTES` and values
    /// of type `STRING` both appear in
    /// \[params\]\[google.spanner.v1.PartitionQueryRequest.params\] as JSON strings.
    ///
    /// In these cases, `param_types` can be used to specify the exact
    /// SQL type for some or all of the SQL query parameters. See the
    /// definition of \[Type\]\[google.spanner.v1.Type\] for more information
    /// about SQL types.
    #[prost(map = "string, message", tag = "5")]
    pub param_types: ::std::collections::HashMap<::prost::alloc::string::String, Type>,
    /// Additional options that affect how many partitions are created.
    #[prost(message, optional, tag = "6")]
    pub partition_options: ::core::option::Option<PartitionOptions>,
}
/// The request for \[PartitionRead\]\[google.spanner.v1.Spanner.PartitionRead\]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PartitionReadRequest {
    /// Required. The session used to create the partitions.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// Read only snapshot transactions are supported, read/write and single use
    /// transactions are not.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<TransactionSelector>,
    /// Required. The name of the table in the database to be read.
    #[prost(string, tag = "3")]
    pub table: ::prost::alloc::string::String,
    /// If non-empty, the name of an index on
    /// \[table\]\[google.spanner.v1.PartitionReadRequest.table\]. This index is used
    /// instead of the table primary key when interpreting
    /// \[key_set\]\[google.spanner.v1.PartitionReadRequest.key_set\] and sorting
    /// result rows. See \[key_set\]\[google.spanner.v1.PartitionReadRequest.key_set\]
    /// for further information.
    #[prost(string, tag = "4")]
    pub index: ::prost::alloc::string::String,
    /// The columns of \[table\]\[google.spanner.v1.PartitionReadRequest.table\] to be
    /// returned for each row matching this request.
    #[prost(string, repeated, tag = "5")]
    pub columns: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Required. `key_set` identifies the rows to be yielded. `key_set` names the
    /// primary keys of the rows in
    /// \[table\]\[google.spanner.v1.PartitionReadRequest.table\] to be yielded, unless
    /// \[index\]\[google.spanner.v1.PartitionReadRequest.index\] is present. If
    /// \[index\]\[google.spanner.v1.PartitionReadRequest.index\] is present, then
    /// \[key_set\]\[google.spanner.v1.PartitionReadRequest.key_set\] instead names
    /// index keys in \[index\]\[google.spanner.v1.PartitionReadRequest.index\].
    ///
    /// It is not an error for the `key_set` to name rows that do not
    /// exist in the database. Read yields nothing for nonexistent rows.
    #[prost(message, optional, tag = "6")]
    pub key_set: ::core::option::Option<KeySet>,
    /// Additional options that affect how many partitions are created.
    #[prost(message, optional, tag = "9")]
    pub partition_options: ::core::option::Option<PartitionOptions>,
}
/// Information returned for each partition returned in a
/// PartitionResponse.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Partition {
    /// This token can be passed to Read, StreamingRead, ExecuteSql, or
    /// ExecuteStreamingSql requests to restrict the results to those identified by
    /// this partition token.
    #[prost(bytes = "vec", tag = "1")]
    pub partition_token: ::prost::alloc::vec::Vec<u8>,
}
/// The response for \[PartitionQuery\]\[google.spanner.v1.Spanner.PartitionQuery\]
/// or \[PartitionRead\]\[google.spanner.v1.Spanner.PartitionRead\]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PartitionResponse {
    /// Partitions created by this request.
    #[prost(message, repeated, tag = "1")]
    pub partitions: ::prost::alloc::vec::Vec<Partition>,
    /// Transaction created by this request.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<Transaction>,
}
/// The request for \[Read\]\[google.spanner.v1.Spanner.Read\] and
/// \[StreamingRead\]\[google.spanner.v1.Spanner.StreamingRead\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ReadRequest {
    /// Required. The session in which the read should be performed.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// The transaction to use. If none is provided, the default is a
    /// temporary read-only transaction with strong concurrency.
    #[prost(message, optional, tag = "2")]
    pub transaction: ::core::option::Option<TransactionSelector>,
    /// Required. The name of the table in the database to be read.
    #[prost(string, tag = "3")]
    pub table: ::prost::alloc::string::String,
    /// If non-empty, the name of an index on
    /// \[table\]\[google.spanner.v1.ReadRequest.table\]. This index is used instead of
    /// the table primary key when interpreting
    /// \[key_set\]\[google.spanner.v1.ReadRequest.key_set\] and sorting result rows.
    /// See \[key_set\]\[google.spanner.v1.ReadRequest.key_set\] for further
    /// information.
    #[prost(string, tag = "4")]
    pub index: ::prost::alloc::string::String,
    /// Required. The columns of \[table\]\[google.spanner.v1.ReadRequest.table\] to be
    /// returned for each row matching this request.
    #[prost(string, repeated, tag = "5")]
    pub columns: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Required. `key_set` identifies the rows to be yielded. `key_set` names the
    /// primary keys of the rows in \[table\]\[google.spanner.v1.ReadRequest.table\] to
    /// be yielded, unless \[index\]\[google.spanner.v1.ReadRequest.index\] is present.
    /// If \[index\]\[google.spanner.v1.ReadRequest.index\] is present, then
    /// \[key_set\]\[google.spanner.v1.ReadRequest.key_set\] instead names index keys
    /// in \[index\]\[google.spanner.v1.ReadRequest.index\].
    ///
    /// If the \[partition_token\]\[google.spanner.v1.ReadRequest.partition_token\]
    /// field is empty, rows are yielded in table primary key order (if
    /// \[index\]\[google.spanner.v1.ReadRequest.index\] is empty) or index key order
    /// (if \[index\]\[google.spanner.v1.ReadRequest.index\] is non-empty).  If the
    /// \[partition_token\]\[google.spanner.v1.ReadRequest.partition_token\] field is
    /// not empty, rows will be yielded in an unspecified order.
    ///
    /// It is not an error for the `key_set` to name rows that do not
    /// exist in the database. Read yields nothing for nonexistent rows.
    #[prost(message, optional, tag = "6")]
    pub key_set: ::core::option::Option<KeySet>,
    /// If greater than zero, only the first `limit` rows are yielded. If `limit`
    /// is zero, the default is no limit. A limit cannot be specified if
    /// `partition_token` is set.
    #[prost(int64, tag = "8")]
    pub limit: i64,
    /// If this request is resuming a previously interrupted read,
    /// `resume_token` should be copied from the last
    /// \[PartialResultSet\]\[google.spanner.v1.PartialResultSet\] yielded before the
    /// interruption. Doing this enables the new read to resume where the last read
    /// left off. The rest of the request parameters must exactly match the request
    /// that yielded this token.
    #[prost(bytes = "vec", tag = "9")]
    pub resume_token: ::prost::alloc::vec::Vec<u8>,
    /// If present, results will be restricted to the specified partition
    /// previously created using PartitionRead().    There must be an exact
    /// match for the values of fields common to this message and the
    /// PartitionReadRequest message used to create this partition_token.
    #[prost(bytes = "vec", tag = "10")]
    pub partition_token: ::prost::alloc::vec::Vec<u8>,
    /// Common options for this request.
    #[prost(message, optional, tag = "11")]
    pub request_options: ::core::option::Option<RequestOptions>,
    /// Directed read options for this request.
    #[prost(message, optional, tag = "14")]
    pub directed_read_options: ::core::option::Option<DirectedReadOptions>,
    /// If this is for a partitioned read and this field is set to `true`, the
    /// request is executed with Spanner Data Boost independent compute resources.
    ///
    /// If the field is set to `true` but the request does not set
    /// `partition_token`, the API returns an `INVALID_ARGUMENT` error.
    #[prost(bool, tag = "15")]
    pub data_boost_enabled: bool,
    /// Optional. Order for the returned rows.
    ///
    /// By default, Spanner will return result rows in primary key order except for
    /// PartitionRead requests. For applications that do not require rows to be
    /// returned in primary key (`ORDER_BY_PRIMARY_KEY`) order, setting
    /// `ORDER_BY_NO_ORDER` option allows Spanner to optimize row retrieval,
    /// resulting in lower latencies in certain cases (e.g. bulk point lookups).
    #[prost(enumeration = "read_request::OrderBy", tag = "16")]
    pub order_by: i32,
    /// Optional. Lock Hint for the request, it can only be used with read-write
    /// transactions.
    #[prost(enumeration = "read_request::LockHint", tag = "17")]
    pub lock_hint: i32,
}
/// Nested message and enum types in `ReadRequest`.
pub mod read_request {
    /// An option to control the order in which rows are returned from a read.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum OrderBy {
        /// Default value.
        ///
        /// ORDER_BY_UNSPECIFIED is equivalent to ORDER_BY_PRIMARY_KEY.
        Unspecified = 0,
        /// Read rows are returned in primary key order.
        ///
        /// In the event that this option is used in conjunction with the
        /// `partition_token` field, the API will return an `INVALID_ARGUMENT` error.
        PrimaryKey = 1,
        /// Read rows are returned in any order.
        NoOrder = 2,
    }
    impl OrderBy {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "ORDER_BY_UNSPECIFIED",
                Self::PrimaryKey => "ORDER_BY_PRIMARY_KEY",
                Self::NoOrder => "ORDER_BY_NO_ORDER",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "ORDER_BY_UNSPECIFIED" => Some(Self::Unspecified),
                "ORDER_BY_PRIMARY_KEY" => Some(Self::PrimaryKey),
                "ORDER_BY_NO_ORDER" => Some(Self::NoOrder),
                _ => None,
            }
        }
    }
    /// A lock hint mechanism for reads done within a transaction.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum LockHint {
        /// Default value.
        ///
        /// LOCK_HINT_UNSPECIFIED is equivalent to LOCK_HINT_SHARED.
        Unspecified = 0,
        /// Acquire shared locks.
        ///
        /// By default when you perform a read as part of a read-write transaction,
        /// Spanner acquires shared read locks, which allows other reads to still
        /// access the data until your transaction is ready to commit. When your
        /// transaction is committing and writes are being applied, the transaction
        /// attempts to upgrade to an exclusive lock for any data you are writing.
        /// For more information about locks, see [Lock
        /// modes](<https://cloud.google.com/spanner/docs/introspection/lock-statistics#explain-lock-modes>).
        Shared = 1,
        /// Acquire exclusive locks.
        ///
        /// Requesting exclusive locks is beneficial if you observe high write
        /// contention, which means you notice that multiple transactions are
        /// concurrently trying to read and write to the same data, resulting in a
        /// large number of aborts. This problem occurs when two transactions
        /// initially acquire shared locks and then both try to upgrade to exclusive
        /// locks at the same time. In this situation both transactions are waiting
        /// for the other to give up their lock, resulting in a deadlocked situation.
        /// Spanner is able to detect this occurring and force one of the
        /// transactions to abort. However, this is a slow and expensive operation
        /// and results in lower performance. In this case it makes sense to acquire
        /// exclusive locks at the start of the transaction because then when
        /// multiple transactions try to act on the same data, they automatically get
        /// serialized. Each transaction waits its turn to acquire the lock and
        /// avoids getting into deadlock situations.
        ///
        /// Because the exclusive lock hint is just a hint, it should not be
        /// considered equivalent to a mutex. In other words, you should not use
        /// Spanner exclusive locks as a mutual exclusion mechanism for the execution
        /// of code outside of Spanner.
        ///
        /// **Note:** Request exclusive locks judiciously because they block others
        /// from reading that data for the entire transaction, rather than just when
        /// the writes are being performed. Unless you observe high write contention,
        /// you should use the default of shared read locks so you don't prematurely
        /// block other clients from reading the data that you're writing to.
        Exclusive = 2,
    }
    impl LockHint {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "LOCK_HINT_UNSPECIFIED",
                Self::Shared => "LOCK_HINT_SHARED",
                Self::Exclusive => "LOCK_HINT_EXCLUSIVE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "LOCK_HINT_UNSPECIFIED" => Some(Self::Unspecified),
                "LOCK_HINT_SHARED" => Some(Self::Shared),
                "LOCK_HINT_EXCLUSIVE" => Some(Self::Exclusive),
                _ => None,
            }
        }
    }
}
/// The request for
/// \[BeginTransaction\]\[google.spanner.v1.Spanner.BeginTransaction\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BeginTransactionRequest {
    /// Required. The session in which the transaction runs.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// Required. Options for the new transaction.
    #[prost(message, optional, tag = "2")]
    pub options: ::core::option::Option<TransactionOptions>,
    /// Common options for this request.
    /// Priority is ignored for this request. Setting the priority in this
    /// request_options struct will not do anything. To set the priority for a
    /// transaction, set it on the reads and writes that are part of this
    /// transaction instead.
    #[prost(message, optional, tag = "3")]
    pub request_options: ::core::option::Option<RequestOptions>,
    /// Optional. Required for read-write transactions on a multiplexed session
    /// that commit mutations but do not perform any reads or queries. Clients
    /// should randomly select one of the mutations from the mutation set and send
    /// it as a part of this request.
    /// This feature is not yet supported and will result in an UNIMPLEMENTED
    /// error.
    #[prost(message, optional, tag = "4")]
    pub mutation_key: ::core::option::Option<Mutation>,
}
/// The request for \[Commit\]\[google.spanner.v1.Spanner.Commit\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CommitRequest {
    /// Required. The session in which the transaction to be committed is running.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// The mutations to be executed when this transaction commits. All
    /// mutations are applied atomically, in the order they appear in
    /// this list.
    #[prost(message, repeated, tag = "4")]
    pub mutations: ::prost::alloc::vec::Vec<Mutation>,
    /// If `true`, then statistics related to the transaction will be included in
    /// the \[CommitResponse\]\[google.spanner.v1.CommitResponse.commit_stats\].
    /// Default value is `false`.
    #[prost(bool, tag = "5")]
    pub return_commit_stats: bool,
    /// Optional. The amount of latency this request is willing to incur in order
    /// to improve throughput. If this field is not set, Spanner assumes requests
    /// are relatively latency sensitive and automatically determines an
    /// appropriate delay time. You can specify a batching delay value between 0
    /// and 500 ms.
    #[prost(message, optional, tag = "8")]
    pub max_commit_delay: ::core::option::Option<::prost_types::Duration>,
    /// Common options for this request.
    #[prost(message, optional, tag = "6")]
    pub request_options: ::core::option::Option<RequestOptions>,
    /// Optional. If the read-write transaction was executed on a multiplexed
    /// session, the precommit token with the highest sequence number received in
    /// this transaction attempt, should be included here. Failing to do so will
    /// result in a FailedPrecondition error.
    /// This feature is not yet supported and will result in an UNIMPLEMENTED
    /// error.
    #[prost(message, optional, tag = "9")]
    pub precommit_token: ::core::option::Option<MultiplexedSessionPrecommitToken>,
    /// Required. The transaction in which to commit.
    #[prost(oneof = "commit_request::Transaction", tags = "2, 3")]
    pub transaction: ::core::option::Option<commit_request::Transaction>,
}
/// Nested message and enum types in `CommitRequest`.
pub mod commit_request {
    /// Required. The transaction in which to commit.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Transaction {
        /// Commit a previously-started transaction.
        #[prost(bytes, tag = "2")]
        TransactionId(::prost::alloc::vec::Vec<u8>),
        /// Execute mutations in a temporary transaction. Note that unlike
        /// commit of a previously-started transaction, commit with a
        /// temporary transaction is non-idempotent. That is, if the
        /// `CommitRequest` is sent to Cloud Spanner more than once (for
        /// instance, due to retries in the application, or in the
        /// transport library), it is possible that the mutations are
        /// executed more than once. If this is undesirable, use
        /// \[BeginTransaction\]\[google.spanner.v1.Spanner.BeginTransaction\] and
        /// \[Commit\]\[google.spanner.v1.Spanner.Commit\] instead.
        #[prost(message, tag = "3")]
        SingleUseTransaction(super::TransactionOptions),
    }
}
/// The request for \[Rollback\]\[google.spanner.v1.Spanner.Rollback\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RollbackRequest {
    /// Required. The session in which the transaction to roll back is running.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// Required. The transaction to roll back.
    #[prost(bytes = "vec", tag = "2")]
    pub transaction_id: ::prost::alloc::vec::Vec<u8>,
}
/// The request for \[BatchWrite\]\[google.spanner.v1.Spanner.BatchWrite\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BatchWriteRequest {
    /// Required. The session in which the batch request is to be run.
    #[prost(string, tag = "1")]
    pub session: ::prost::alloc::string::String,
    /// Common options for this request.
    #[prost(message, optional, tag = "3")]
    pub request_options: ::core::option::Option<RequestOptions>,
    /// Required. The groups of mutations to be applied.
    #[prost(message, repeated, tag = "4")]
    pub mutation_groups: ::prost::alloc::vec::Vec<batch_write_request::MutationGroup>,
    /// Optional. When `exclude_txn_from_change_streams` is set to `true`:
    ///
    /// * Mutations from all transactions in this batch write operation will not
    ///   be recorded in change streams with DDL option `allow_txn_exclusion=true`
    ///   that are tracking columns modified by these transactions.
    /// * Mutations from all transactions in this batch write operation will be
    ///   recorded in change streams with DDL option `allow_txn_exclusion=false or   not set` that are tracking columns modified by these transactions.
    ///
    /// When `exclude_txn_from_change_streams` is set to `false` or not set,
    /// mutations from all transactions in this batch write operation will be
    /// recorded in all change streams that are tracking columns modified by these
    /// transactions.
    #[prost(bool, tag = "5")]
    pub exclude_txn_from_change_streams: bool,
}
/// Nested message and enum types in `BatchWriteRequest`.
pub mod batch_write_request {
    /// A group of mutations to be committed together. Related mutations should be
    /// placed in a group. For example, two mutations inserting rows with the same
    /// primary key prefix in both parent and child tables are related.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct MutationGroup {
        /// Required. The mutations in this group.
        #[prost(message, repeated, tag = "1")]
        pub mutations: ::prost::alloc::vec::Vec<super::Mutation>,
    }
}
/// The result of applying a batch of mutations.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BatchWriteResponse {
    /// The mutation groups applied in this batch. The values index into the
    /// `mutation_groups` field in the corresponding `BatchWriteRequest`.
    #[prost(int32, repeated, tag = "1")]
    pub indexes: ::prost::alloc::vec::Vec<i32>,
    /// An `OK` status indicates success. Any other status indicates a failure.
    #[prost(message, optional, tag = "2")]
    pub status: ::core::option::Option<super::super::rpc::Status>,
    /// The commit timestamp of the transaction that applied this batch.
    /// Present if `status` is `OK`, absent otherwise.
    #[prost(message, optional, tag = "3")]
    pub commit_timestamp: ::core::option::Option<::prost_types::Timestamp>,
}
/// Generated client implementations.
pub mod spanner_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// Cloud Spanner API
    ///
    /// The Cloud Spanner API can be used to manage sessions and execute
    /// transactions on data stored in Cloud Spanner databases.
    #[derive(Debug, Clone)]
    pub struct SpannerClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl SpannerClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> SpannerClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> SpannerClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            SpannerClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Creates a new session. A session can be used to perform
        /// transactions that read and/or modify data in a Cloud Spanner database.
        /// Sessions are meant to be reused for many consecutive
        /// transactions.
        ///
        /// Sessions can only execute one transaction at a time. To execute
        /// multiple concurrent read-write/write-only transactions, create
        /// multiple sessions. Note that standalone reads and queries use a
        /// transaction internally, and count toward the one transaction
        /// limit.
        ///
        /// Active sessions use additional server resources, so it is a good idea to
        /// delete idle and unneeded sessions.
        /// Aside from explicit deletes, Cloud Spanner may delete sessions for which no
        /// operations are sent for more than an hour. If a session is deleted,
        /// requests to it return `NOT_FOUND`.
        ///
        /// Idle sessions can be kept alive by sending a trivial SQL query
        /// periodically, e.g., `"SELECT 1"`.
        pub async fn create_session(
            &mut self,
            request: impl tonic::IntoRequest<super::CreateSessionRequest>,
        ) -> std::result::Result<tonic::Response<super::Session>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/CreateSession",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "CreateSession"));
            self.inner.unary(req, path, codec).await
        }
        /// Creates multiple new sessions.
        ///
        /// This API can be used to initialize a session cache on the clients.
        /// See https://goo.gl/TgSFN2 for best practices on session cache management.
        pub async fn batch_create_sessions(
            &mut self,
            request: impl tonic::IntoRequest<super::BatchCreateSessionsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::BatchCreateSessionsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/BatchCreateSessions",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new("google.spanner.v1.Spanner", "BatchCreateSessions"),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Gets a session. Returns `NOT_FOUND` if the session does not exist.
        /// This is mainly useful for determining whether a session is still
        /// alive.
        pub async fn get_session(
            &mut self,
            request: impl tonic::IntoRequest<super::GetSessionRequest>,
        ) -> std::result::Result<tonic::Response<super::Session>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/GetSession",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "GetSession"));
            self.inner.unary(req, path, codec).await
        }
        /// Lists all sessions in a given database.
        pub async fn list_sessions(
            &mut self,
            request: impl tonic::IntoRequest<super::ListSessionsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ListSessionsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/ListSessions",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "ListSessions"));
            self.inner.unary(req, path, codec).await
        }
        /// Ends a session, releasing server resources associated with it. This will
        /// asynchronously trigger cancellation of any operations that are running with
        /// this session.
        pub async fn delete_session(
            &mut self,
            request: impl tonic::IntoRequest<super::DeleteSessionRequest>,
        ) -> std::result::Result<tonic::Response<()>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/DeleteSession",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "DeleteSession"));
            self.inner.unary(req, path, codec).await
        }
        /// Executes an SQL statement, returning all results in a single reply. This
        /// method cannot be used to return a result set larger than 10 MiB;
        /// if the query yields more data than that, the query fails with
        /// a `FAILED_PRECONDITION` error.
        ///
        /// Operations inside read-write transactions might return `ABORTED`. If
        /// this occurs, the application should restart the transaction from
        /// the beginning. See \[Transaction\]\[google.spanner.v1.Transaction\] for more
        /// details.
        ///
        /// Larger result sets can be fetched in streaming fashion by calling
        /// \[ExecuteStreamingSql\]\[google.spanner.v1.Spanner.ExecuteStreamingSql\]
        /// instead.
        pub async fn execute_sql(
            &mut self,
            request: impl tonic::IntoRequest<super::ExecuteSqlRequest>,
        ) -> std::result::Result<tonic::Response<super::ResultSet>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/ExecuteSql",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "ExecuteSql"));
            self.inner.unary(req, path, codec).await
        }
        /// Like \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\], except returns the
        /// result set as a stream. Unlike
        /// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\], there is no limit on
        /// the size of the returned result set. However, no individual row in the
        /// result set can exceed 100 MiB, and no column value can exceed 10 MiB.
        pub async fn execute_streaming_sql(
            &mut self,
            request: impl tonic::IntoRequest<super::ExecuteSqlRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::PartialResultSet>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/ExecuteStreamingSql",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new("google.spanner.v1.Spanner", "ExecuteStreamingSql"),
                );
            self.inner.server_streaming(req, path, codec).await
        }
        /// Executes a batch of SQL DML statements. This method allows many statements
        /// to be run with lower latency than submitting them sequentially with
        /// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\].
        ///
        /// Statements are executed in sequential order. A request can succeed even if
        /// a statement fails. The
        /// \[ExecuteBatchDmlResponse.status\]\[google.spanner.v1.ExecuteBatchDmlResponse.status\]
        /// field in the response provides information about the statement that failed.
        /// Clients must inspect this field to determine whether an error occurred.
        ///
        /// Execution stops after the first failed statement; the remaining statements
        /// are not executed.
        pub async fn execute_batch_dml(
            &mut self,
            request: impl tonic::IntoRequest<super::ExecuteBatchDmlRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ExecuteBatchDmlResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/ExecuteBatchDml",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "ExecuteBatchDml"));
            self.inner.unary(req, path, codec).await
        }
        /// Reads rows from the database using key lookups and scans, as a
        /// simple key/value style alternative to
        /// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\].  This method cannot be
        /// used to return a result set larger than 10 MiB; if the read matches more
        /// data than that, the read fails with a `FAILED_PRECONDITION`
        /// error.
        ///
        /// Reads inside read-write transactions might return `ABORTED`. If
        /// this occurs, the application should restart the transaction from
        /// the beginning. See \[Transaction\]\[google.spanner.v1.Transaction\] for more
        /// details.
        ///
        /// Larger result sets can be yielded in streaming fashion by calling
        /// \[StreamingRead\]\[google.spanner.v1.Spanner.StreamingRead\] instead.
        pub async fn read(
            &mut self,
            request: impl tonic::IntoRequest<super::ReadRequest>,
        ) -> std::result::Result<tonic::Response<super::ResultSet>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/Read",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "Read"));
            self.inner.unary(req, path, codec).await
        }
        /// Like \[Read\]\[google.spanner.v1.Spanner.Read\], except returns the result set
        /// as a stream. Unlike \[Read\]\[google.spanner.v1.Spanner.Read\], there is no
        /// limit on the size of the returned result set. However, no individual row in
        /// the result set can exceed 100 MiB, and no column value can exceed
        /// 10 MiB.
        pub async fn streaming_read(
            &mut self,
            request: impl tonic::IntoRequest<super::ReadRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::PartialResultSet>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/StreamingRead",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "StreamingRead"));
            self.inner.server_streaming(req, path, codec).await
        }
        /// Begins a new transaction. This step can often be skipped:
        /// \[Read\]\[google.spanner.v1.Spanner.Read\],
        /// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\] and
        /// \[Commit\]\[google.spanner.v1.Spanner.Commit\] can begin a new transaction as a
        /// side-effect.
        pub async fn begin_transaction(
            &mut self,
            request: impl tonic::IntoRequest<super::BeginTransactionRequest>,
        ) -> std::result::Result<tonic::Response<super::Transaction>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/BeginTransaction",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new("google.spanner.v1.Spanner", "BeginTransaction"),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Commits a transaction. The request includes the mutations to be
        /// applied to rows in the database.
        ///
        /// `Commit` might return an `ABORTED` error. This can occur at any time;
        /// commonly, the cause is conflicts with concurrent
        /// transactions. However, it can also happen for a variety of other
        /// reasons. If `Commit` returns `ABORTED`, the caller should re-attempt
        /// the transaction from the beginning, re-using the same session.
        ///
        /// On very rare occasions, `Commit` might return `UNKNOWN`. This can happen,
        /// for example, if the client job experiences a 1+ hour networking failure.
        /// At that point, Cloud Spanner has lost track of the transaction outcome and
        /// we recommend that you perform another read from the database to see the
        /// state of things as they are now.
        pub async fn commit(
            &mut self,
            request: impl tonic::IntoRequest<super::CommitRequest>,
        ) -> std::result::Result<tonic::Response<super::CommitResponse>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/Commit",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "Commit"));
            self.inner.unary(req, path, codec).await
        }
        /// Rolls back a transaction, releasing any locks it holds. It is a good
        /// idea to call this for any transaction that includes one or more
        /// \[Read\]\[google.spanner.v1.Spanner.Read\] or
        /// \[ExecuteSql\]\[google.spanner.v1.Spanner.ExecuteSql\] requests and ultimately
        /// decides not to commit.
        ///
        /// `Rollback` returns `OK` if it successfully aborts the transaction, the
        /// transaction was already aborted, or the transaction is not
        /// found. `Rollback` never returns `ABORTED`.
        pub async fn rollback(
            &mut self,
            request: impl tonic::IntoRequest<super::RollbackRequest>,
        ) -> std::result::Result<tonic::Response<()>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/Rollback",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "Rollback"));
            self.inner.unary(req, path, codec).await
        }
        /// Creates a set of partition tokens that can be used to execute a query
        /// operation in parallel.  Each of the returned partition tokens can be used
        /// by \[ExecuteStreamingSql\]\[google.spanner.v1.Spanner.ExecuteStreamingSql\] to
        /// specify a subset of the query result to read.  The same session and
        /// read-only transaction must be used by the PartitionQueryRequest used to
        /// create the partition tokens and the ExecuteSqlRequests that use the
        /// partition tokens.
        ///
        /// Partition tokens become invalid when the session used to create them
        /// is deleted, is idle for too long, begins a new transaction, or becomes too
        /// old.  When any of these happen, it is not possible to resume the query, and
        /// the whole operation must be restarted from the beginning.
        pub async fn partition_query(
            &mut self,
            request: impl tonic::IntoRequest<super::PartitionQueryRequest>,
        ) -> std::result::Result<
            tonic::Response<super::PartitionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/PartitionQuery",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "PartitionQuery"));
            self.inner.unary(req, path, codec).await
        }
        /// Creates a set of partition tokens that can be used to execute a read
        /// operation in parallel.  Each of the returned partition tokens can be used
        /// by \[StreamingRead\]\[google.spanner.v1.Spanner.StreamingRead\] to specify a
        /// subset of the read result to read.  The same session and read-only
        /// transaction must be used by the PartitionReadRequest used to create the
        /// partition tokens and the ReadRequests that use the partition tokens.  There
        /// are no ordering guarantees on rows returned among the returned partition
        /// tokens, or even within each individual StreamingRead call issued with a
        /// partition_token.
        ///
        /// Partition tokens become invalid when the session used to create them
        /// is deleted, is idle for too long, begins a new transaction, or becomes too
        /// old.  When any of these happen, it is not possible to resume the read, and
        /// the whole operation must be restarted from the beginning.
        pub async fn partition_read(
            &mut self,
            request: impl tonic::IntoRequest<super::PartitionReadRequest>,
        ) -> std::result::Result<
            tonic::Response<super::PartitionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/PartitionRead",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "PartitionRead"));
            self.inner.unary(req, path, codec).await
        }
        /// Batches the supplied mutation groups in a collection of efficient
        /// transactions. All mutations in a group are committed atomically. However,
        /// mutations across groups can be committed non-atomically in an unspecified
        /// order and thus, they must be independent of each other. Partial failure is
        /// possible, i.e., some groups may have been committed successfully, while
        /// some may have failed. The results of individual batches are streamed into
        /// the response as the batches are applied.
        ///
        /// BatchWrite requests are not replay protected, meaning that each mutation
        /// group may be applied more than once. Replays of non-idempotent mutations
        /// may have undesirable effects. For example, replays of an insert mutation
        /// may produce an already exists error or if you use generated or commit
        /// timestamp-based keys, it may result in additional rows being added to the
        /// mutation's table. We recommend structuring your mutation groups to be
        /// idempotent to avoid this issue.
        pub async fn batch_write(
            &mut self,
            request: impl tonic::IntoRequest<super::BatchWriteRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::BatchWriteResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.spanner.v1.Spanner/BatchWrite",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("google.spanner.v1.Spanner", "BatchWrite"));
            self.inner.server_streaming(req, path, codec).await
        }
    }
}
/// Spanner Change Streams enable customers to capture and stream out changes to
/// their Spanner databases in real-time. A change stream
/// can be created with option partition_mode='IMMUTABLE_KEY_RANGE' or
/// partition_mode='MUTABLE_KEY_RANGE'.
///
/// This message is only used in Change Streams created with the option
/// partition_mode='MUTABLE_KEY_RANGE'. Spanner automatically creates a special
/// Table-Valued Function (TVF) along with each Change Streams. The function
/// provides access to the change stream's records. The function is named
/// READ\_\<change_stream_name> (where \<change_stream_name> is the
/// name of the change stream), and it returns a table with only one column
/// called ChangeRecord.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChangeStreamRecord {
    /// One of the change stream subrecords.
    #[prost(oneof = "change_stream_record::Record", tags = "1, 2, 3, 4, 5")]
    pub record: ::core::option::Option<change_stream_record::Record>,
}
/// Nested message and enum types in `ChangeStreamRecord`.
pub mod change_stream_record {
    /// A data change record contains a set of changes to a table with the same
    /// modification type (insert, update, or delete) committed at the same commit
    /// timestamp in one change stream partition for the same transaction. Multiple
    /// data change records can be returned for the same transaction across
    /// multiple change stream partitions.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct DataChangeRecord {
        /// Indicates the timestamp in which the change was committed.
        /// DataChangeRecord.commit_timestamps,
        /// PartitionStartRecord.start_timestamps,
        /// PartitionEventRecord.commit_timestamps, and
        /// PartitionEndRecord.end_timestamps can have the same value in the same
        /// partition.
        #[prost(message, optional, tag = "1")]
        pub commit_timestamp: ::core::option::Option<::prost_types::Timestamp>,
        /// Record sequence numbers are unique and monotonically increasing (but not
        /// necessarily contiguous) for a specific timestamp across record
        /// types in the same partition. To guarantee ordered processing, the reader
        /// should process records (of potentially different types) in
        /// record_sequence order for a specific timestamp in the same partition.
        ///
        /// The record sequence number ordering across partitions is only meaningful
        /// in the context of a specific transaction. Record sequence numbers are
        /// unique across partitions for a specific transaction. Sort the
        /// DataChangeRecords for the same
        /// \[server_transaction_id\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.server_transaction_id\]
        /// by
        /// \[record_sequence\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.record_sequence\]
        /// to reconstruct the ordering of the changes within the transaction.
        #[prost(string, tag = "2")]
        pub record_sequence: ::prost::alloc::string::String,
        /// Provides a globally unique string that represents the transaction in
        /// which the change was committed. Multiple transactions can have the same
        /// commit timestamp, but each transaction has a unique
        /// server_transaction_id.
        #[prost(string, tag = "3")]
        pub server_transaction_id: ::prost::alloc::string::String,
        /// Indicates whether this is the last record for a transaction in the
        /// current partition. Clients can use this field to determine when all
        /// records for a transaction in the current partition have been received.
        #[prost(bool, tag = "4")]
        pub is_last_record_in_transaction_in_partition: bool,
        /// Name of the table affected by the change.
        #[prost(string, tag = "5")]
        pub table: ::prost::alloc::string::String,
        /// Provides metadata describing the columns associated with the
        /// \[mods\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.mods\] listed
        /// below.
        #[prost(message, repeated, tag = "6")]
        pub column_metadata: ::prost::alloc::vec::Vec<
            data_change_record::ColumnMetadata,
        >,
        /// Describes the changes that were made.
        #[prost(message, repeated, tag = "7")]
        pub mods: ::prost::alloc::vec::Vec<data_change_record::Mod>,
        /// Describes the type of change.
        #[prost(enumeration = "data_change_record::ModType", tag = "8")]
        pub mod_type: i32,
        /// Describes the value capture type that was specified in the change stream
        /// configuration when this change was captured.
        #[prost(enumeration = "data_change_record::ValueCaptureType", tag = "9")]
        pub value_capture_type: i32,
        /// Indicates the number of data change records that are part of this
        /// transaction across all change stream partitions. This value can be used
        /// to assemble all the records associated with a particular transaction.
        #[prost(int32, tag = "10")]
        pub number_of_records_in_transaction: i32,
        /// Indicates the number of partitions that return data change records for
        /// this transaction. This value can be helpful in assembling all records
        /// associated with a particular transaction.
        #[prost(int32, tag = "11")]
        pub number_of_partitions_in_transaction: i32,
        /// Indicates the transaction tag associated with this transaction.
        #[prost(string, tag = "12")]
        pub transaction_tag: ::prost::alloc::string::String,
        /// Indicates whether the transaction is a system transaction. System
        /// transactions include those issued by time-to-live (TTL), column backfill,
        /// etc.
        #[prost(bool, tag = "13")]
        pub is_system_transaction: bool,
    }
    /// Nested message and enum types in `DataChangeRecord`.
    pub mod data_change_record {
        /// Metadata for a column.
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct ColumnMetadata {
            /// Name of the column.
            #[prost(string, tag = "1")]
            pub name: ::prost::alloc::string::String,
            /// Type of the column.
            #[prost(message, optional, tag = "2")]
            pub r#type: ::core::option::Option<super::super::Type>,
            /// Indicates whether the column is a primary key column.
            #[prost(bool, tag = "3")]
            pub is_primary_key: bool,
            /// Ordinal position of the column based on the original table definition
            /// in the schema starting with a value of 1.
            #[prost(int64, tag = "4")]
            pub ordinal_position: i64,
        }
        /// Returns the value and associated metadata for a particular field of the
        /// \[Mod\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.Mod\].
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct ModValue {
            /// Index within the repeated
            /// \[column_metadata\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.column_metadata\]
            /// field, to obtain the column metadata for the column that was modified.
            #[prost(int32, tag = "1")]
            pub column_metadata_index: i32,
            /// The value of the column.
            #[prost(message, optional, tag = "2")]
            pub value: ::core::option::Option<::prost_types::Value>,
        }
        /// A mod describes all data changes in a watched table row.
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct Mod {
            /// Returns the value of the primary key of the modified row.
            #[prost(message, repeated, tag = "1")]
            pub keys: ::prost::alloc::vec::Vec<ModValue>,
            /// Returns the old values before the change for the modified columns.
            /// Always empty for
            /// \[INSERT\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.ModType.INSERT\],
            /// or if old values are not being captured specified by
            /// \[value_capture_type\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.ValueCaptureType\].
            #[prost(message, repeated, tag = "2")]
            pub old_values: ::prost::alloc::vec::Vec<ModValue>,
            /// Returns the new values after the change for the modified columns.
            /// Always empty for
            /// \[DELETE\]\[google.spanner.v1.ChangeStreamRecord.DataChangeRecord.ModType.DELETE\].
            #[prost(message, repeated, tag = "3")]
            pub new_values: ::prost::alloc::vec::Vec<ModValue>,
        }
        /// Mod type describes the type of change Spanner applied to the data. For
        /// example, if the client submits an INSERT_OR_UPDATE request, Spanner will
        /// perform an insert if there is no existing row and return ModType INSERT.
        /// Alternatively, if there is an existing row, Spanner will perform an
        /// update and return ModType UPDATE.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum ModType {
            /// Not specified.
            Unspecified = 0,
            /// Indicates data was inserted.
            Insert = 10,
            /// Indicates existing data was updated.
            Update = 20,
            /// Indicates existing data was deleted.
            Delete = 30,
        }
        impl ModType {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "MOD_TYPE_UNSPECIFIED",
                    Self::Insert => "INSERT",
                    Self::Update => "UPDATE",
                    Self::Delete => "DELETE",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "MOD_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                    "INSERT" => Some(Self::Insert),
                    "UPDATE" => Some(Self::Update),
                    "DELETE" => Some(Self::Delete),
                    _ => None,
                }
            }
        }
        /// Value capture type describes which values are recorded in the data
        /// change record.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum ValueCaptureType {
            /// Not specified.
            Unspecified = 0,
            /// Records both old and new values of the modified watched columns.
            OldAndNewValues = 10,
            /// Records only new values of the modified watched columns.
            NewValues = 20,
            /// Records new values of all watched columns, including modified and
            /// unmodified columns.
            NewRow = 30,
            /// Records the new values of all watched columns, including modified and
            /// unmodified columns. Also records the old values of the modified
            /// columns.
            NewRowAndOldValues = 40,
        }
        impl ValueCaptureType {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "VALUE_CAPTURE_TYPE_UNSPECIFIED",
                    Self::OldAndNewValues => "OLD_AND_NEW_VALUES",
                    Self::NewValues => "NEW_VALUES",
                    Self::NewRow => "NEW_ROW",
                    Self::NewRowAndOldValues => "NEW_ROW_AND_OLD_VALUES",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "VALUE_CAPTURE_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                    "OLD_AND_NEW_VALUES" => Some(Self::OldAndNewValues),
                    "NEW_VALUES" => Some(Self::NewValues),
                    "NEW_ROW" => Some(Self::NewRow),
                    "NEW_ROW_AND_OLD_VALUES" => Some(Self::NewRowAndOldValues),
                    _ => None,
                }
            }
        }
    }
    /// A heartbeat record is returned as a progress indicator, when there are no
    /// data changes or any other partition record types in the change stream
    /// partition.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct HeartbeatRecord {
        /// Indicates the timestamp at which the query has returned all the records
        /// in the change stream partition with timestamp \<= heartbeat timestamp.
        /// The heartbeat timestamp will not be the same as the timestamps of other
        /// record types in the same partition.
        #[prost(message, optional, tag = "1")]
        pub timestamp: ::core::option::Option<::prost_types::Timestamp>,
    }
    /// A partition start record serves as a notification that the client should
    /// schedule the partitions to be queried. PartitionStartRecord returns
    /// information about one or more partitions.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct PartitionStartRecord {
        /// Start timestamp at which the partitions should be queried to return
        /// change stream records with timestamps >= start_timestamp.
        /// DataChangeRecord.commit_timestamps,
        /// PartitionStartRecord.start_timestamps,
        /// PartitionEventRecord.commit_timestamps, and
        /// PartitionEndRecord.end_timestamps can have the same value in the same
        /// partition.
        #[prost(message, optional, tag = "1")]
        pub start_timestamp: ::core::option::Option<::prost_types::Timestamp>,
        /// Record sequence numbers are unique and monotonically increasing (but not
        /// necessarily contiguous) for a specific timestamp across record
        /// types in the same partition. To guarantee ordered processing, the reader
        /// should process records (of potentially different types) in
        /// record_sequence order for a specific timestamp in the same partition.
        #[prost(string, tag = "2")]
        pub record_sequence: ::prost::alloc::string::String,
        /// Unique partition identifiers to be used in queries.
        #[prost(string, repeated, tag = "3")]
        pub partition_tokens: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    }
    /// A partition end record serves as a notification that the client should stop
    /// reading the partition. No further records are expected to be retrieved on
    /// it.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct PartitionEndRecord {
        /// End timestamp at which the change stream partition is terminated. All
        /// changes generated by this partition will have timestamps \<=
        /// end_timestamp. DataChangeRecord.commit_timestamps,
        /// PartitionStartRecord.start_timestamps,
        /// PartitionEventRecord.commit_timestamps, and
        /// PartitionEndRecord.end_timestamps can have the same value in the same
        /// partition. PartitionEndRecord is the last record returned for a
        /// partition.
        #[prost(message, optional, tag = "1")]
        pub end_timestamp: ::core::option::Option<::prost_types::Timestamp>,
        /// Record sequence numbers are unique and monotonically increasing (but not
        /// necessarily contiguous) for a specific timestamp across record
        /// types in the same partition. To guarantee ordered processing, the reader
        /// should process records (of potentially different types) in
        /// record_sequence order for a specific timestamp in the same partition.
        #[prost(string, tag = "2")]
        pub record_sequence: ::prost::alloc::string::String,
        /// Unique partition identifier describing the terminated change stream
        /// partition.
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEndRecord.partition_token\]
        /// is equal to the partition token of the change stream partition currently
        /// queried to return this PartitionEndRecord.
        #[prost(string, tag = "3")]
        pub partition_token: ::prost::alloc::string::String,
    }
    /// A partition event record describes key range changes for a change stream
    /// partition. The changes to a row defined by its primary key can be captured
    /// in one change stream partition for a specific time range, and then be
    /// captured in a different change stream partition for a different time range.
    /// This movement of key ranges across change stream partitions is a reflection
    /// of activities, such as Spanner's dynamic splitting and load balancing, etc.
    /// Processing this event is needed if users want to guarantee processing of
    /// the changes for any key in timestamp order. If time ordered processing of
    /// changes for a primary key is not needed, this event can be ignored.
    /// To guarantee time ordered processing for each primary key, if the event
    /// describes move-ins, the reader of this partition needs to wait until the
    /// readers of the source partitions have processed all records with timestamps
    /// \<= this PartitionEventRecord.commit_timestamp, before advancing beyond this
    /// PartitionEventRecord. If the event describes move-outs, the reader can
    /// notify the readers of the destination partitions that they can continue
    /// processing.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct PartitionEventRecord {
        /// Indicates the commit timestamp at which the key range change occurred.
        /// DataChangeRecord.commit_timestamps,
        /// PartitionStartRecord.start_timestamps,
        /// PartitionEventRecord.commit_timestamps, and
        /// PartitionEndRecord.end_timestamps can have the same value in the same
        /// partition.
        #[prost(message, optional, tag = "1")]
        pub commit_timestamp: ::core::option::Option<::prost_types::Timestamp>,
        /// Record sequence numbers are unique and monotonically increasing (but not
        /// necessarily contiguous) for a specific timestamp across record
        /// types in the same partition. To guarantee ordered processing, the reader
        /// should process records (of potentially different types) in
        /// record_sequence order for a specific timestamp in the same partition.
        #[prost(string, tag = "2")]
        pub record_sequence: ::prost::alloc::string::String,
        /// Unique partition identifier describing the partition this event
        /// occurred on.
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\]
        /// is equal to the partition token of the change stream partition currently
        /// queried to return this PartitionEventRecord.
        #[prost(string, tag = "3")]
        pub partition_token: ::prost::alloc::string::String,
        /// Set when one or more key ranges are moved into the change stream
        /// partition identified by
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\].
        ///
        /// Example: Two key ranges are moved into partition (P1) from partition (P2)
        /// and partition (P3) in a single transaction at timestamp T.
        ///
        /// The PartitionEventRecord returned in P1 will reflect the move as:
        ///
        /// PartitionEventRecord {
        /// commit_timestamp: T
        /// partition_token: "P1"
        /// move_in_events {
        /// source_partition_token: "P2"
        /// }
        /// move_in_events {
        /// source_partition_token: "P3"
        /// }
        /// }
        ///
        /// The PartitionEventRecord returned in P2 will reflect the move as:
        ///
        /// PartitionEventRecord {
        /// commit_timestamp: T
        /// partition_token: "P2"
        /// move_out_events {
        /// destination_partition_token: "P1"
        /// }
        /// }
        ///
        /// The PartitionEventRecord returned in P3 will reflect the move as:
        ///
        /// PartitionEventRecord {
        /// commit_timestamp: T
        /// partition_token: "P3"
        /// move_out_events {
        /// destination_partition_token: "P1"
        /// }
        /// }
        #[prost(message, repeated, tag = "4")]
        pub move_in_events: ::prost::alloc::vec::Vec<
            partition_event_record::MoveInEvent,
        >,
        /// Set when one or more key ranges are moved out of the change stream
        /// partition identified by
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\].
        ///
        /// Example: Two key ranges are moved out of partition (P1) to partition (P2)
        /// and partition (P3) in a single transaction at timestamp T.
        ///
        /// The PartitionEventRecord returned in P1 will reflect the move as:
        ///
        /// PartitionEventRecord {
        /// commit_timestamp: T
        /// partition_token: "P1"
        /// move_out_events {
        /// destination_partition_token: "P2"
        /// }
        /// move_out_events {
        /// destination_partition_token: "P3"
        /// }
        /// }
        ///
        /// The PartitionEventRecord returned in P2 will reflect the move as:
        ///
        /// PartitionEventRecord {
        /// commit_timestamp: T
        /// partition_token: "P2"
        /// move_in_events {
        /// source_partition_token: "P1"
        /// }
        /// }
        ///
        /// The PartitionEventRecord returned in P3 will reflect the move as:
        ///
        /// PartitionEventRecord {
        /// commit_timestamp: T
        /// partition_token: "P3"
        /// move_in_events {
        /// source_partition_token: "P1"
        /// }
        /// }
        #[prost(message, repeated, tag = "5")]
        pub move_out_events: ::prost::alloc::vec::Vec<
            partition_event_record::MoveOutEvent,
        >,
    }
    /// Nested message and enum types in `PartitionEventRecord`.
    pub mod partition_event_record {
        /// Describes move-in of the key ranges into the change stream partition
        /// identified by
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\].
        ///
        /// To maintain processing the changes for a particular key in timestamp
        /// order, the query processing the change stream partition identified by
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\]
        /// should not advance beyond the partition event record commit timestamp
        /// until the queries processing the source change stream partitions have
        /// processed all change stream records with timestamps \<= the partition
        /// event record commit timestamp.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct MoveInEvent {
            /// An unique partition identifier describing the source change stream
            /// partition that recorded changes for the key range that is moving
            /// into this partition.
            #[prost(string, tag = "1")]
            pub source_partition_token: ::prost::alloc::string::String,
        }
        /// Describes move-out of the key ranges out of the change stream partition
        /// identified by
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\].
        ///
        /// To maintain processing the changes for a particular key in timestamp
        /// order, the query processing the
        /// \[MoveOutEvent\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.MoveOutEvent\]
        /// in the partition identified by
        /// \[partition_token\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.partition_token\]
        /// should inform the queries processing the destination partitions that
        /// they can unblock and proceed processing records past the
        /// \[commit_timestamp\]\[google.spanner.v1.ChangeStreamRecord.PartitionEventRecord.commit_timestamp\].
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct MoveOutEvent {
            /// An unique partition identifier describing the destination change
            /// stream partition that will record changes for the key range that is
            /// moving out of this partition.
            #[prost(string, tag = "1")]
            pub destination_partition_token: ::prost::alloc::string::String,
        }
    }
    /// One of the change stream subrecords.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Record {
        /// Data change record describing a data change for a change stream
        /// partition.
        #[prost(message, tag = "1")]
        DataChangeRecord(DataChangeRecord),
        /// Heartbeat record describing a heartbeat for a change stream partition.
        #[prost(message, tag = "2")]
        HeartbeatRecord(HeartbeatRecord),
        /// Partition start record describing a new change stream partition.
        #[prost(message, tag = "3")]
        PartitionStartRecord(PartitionStartRecord),
        /// Partition end record describing a terminated change stream partition.
        #[prost(message, tag = "4")]
        PartitionEndRecord(PartitionEndRecord),
        /// Partition event record describing key range changes for a change stream
        /// partition.
        #[prost(message, tag = "5")]
        PartitionEventRecord(PartitionEventRecord),
    }
}
