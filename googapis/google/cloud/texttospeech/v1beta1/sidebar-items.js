initSidebarItems({"enum":[["AudioEncoding","Configuration to set up audio encoder. The encoding determines the output audio format that weâ€™d like."],["SsmlVoiceGender","Gender of the voice as described in SSML voice element."]],"mod":[["custom_voice_params","Nested message and enum types in `CustomVoiceParams`."],["synthesis_input","Nested message and enum types in `SynthesisInput`."],["synthesize_speech_request","Nested message and enum types in `SynthesizeSpeechRequest`."],["text_to_speech_client","Generated client implementations."]],"struct":[["AudioConfig","Description of audio data to be synthesized."],["CustomVoiceParams","Description of the custom voice to be synthesized."],["ListVoicesRequest","The top-level message sent by the client for the `ListVoices` method."],["ListVoicesResponse","The message returned to the client by the `ListVoices` method."],["SynthesisInput","Contains text input to be synthesized. Either `text` or `ssml` must be supplied. Supplying both or neither returns [google.rpc.Code.INVALID_ARGUMENT][]. The input size is limited to 5000 characters."],["SynthesizeSpeechRequest","The top-level message sent by the client for the `SynthesizeSpeech` method."],["SynthesizeSpeechResponse","The message returned to the client by the `SynthesizeSpeech` method."],["Timepoint","This contains a mapping between a certain point in the input text and a corresponding time in the output audio."],["Voice","Description of a voice supported by the TTS service."],["VoiceSelectionParams","Description of which voice to use for a synthesis request."]]});