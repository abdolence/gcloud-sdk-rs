initSidebarItems({"mod":[["adaptation_client","Generated client implementations."],["custom_class","Nested message and enum types in `CustomClass`."],["phrase_set","Nested message and enum types in `PhraseSet`."],["recognition_audio","Nested message and enum types in `RecognitionAudio`."],["recognition_config","Nested message and enum types in `RecognitionConfig`."],["recognition_metadata","Nested message and enum types in `RecognitionMetadata`."],["speech_client","Generated client implementations."],["streaming_recognize_request","Nested message and enum types in `StreamingRecognizeRequest`."],["streaming_recognize_response","Nested message and enum types in `StreamingRecognizeResponse`."],["transcript_normalization","Nested message and enum types in `TranscriptNormalization`."],["transcript_output_config","Nested message and enum types in `TranscriptOutputConfig`."]],"struct":[["CreateCustomClassRequest","Message sent by the client for the `CreateCustomClass` method."],["CreatePhraseSetRequest","Message sent by the client for the `CreatePhraseSet` method."],["CustomClass","A set of words or phrases that represents a common concept likely to appear in your audio, for example a list of passenger ship names. CustomClass items can be substituted into placeholders that you set in PhraseSet phrases."],["DeleteCustomClassRequest","Message sent by the client for the `DeleteCustomClass` method."],["DeletePhraseSetRequest","Message sent by the client for the `DeletePhraseSet` method."],["GetCustomClassRequest","Message sent by the client for the `GetCustomClass` method."],["GetPhraseSetRequest","Message sent by the client for the `GetPhraseSet` method."],["ListCustomClassesRequest","Message sent by the client for the `ListCustomClasses` method."],["ListCustomClassesResponse","Message returned to the client by the `ListCustomClasses` method."],["ListPhraseSetRequest","Message sent by the client for the `ListPhraseSet` method."],["ListPhraseSetResponse","Message returned to the client by the `ListPhraseSet` method."],["LongRunningRecognizeMetadata","Describes the progress of a long-running `LongRunningRecognize` call. It is included in the `metadata` field of the `Operation` returned by the `GetOperation` call of the `google::longrunning::Operations` service."],["LongRunningRecognizeRequest","The top-level message sent by the client for the `LongRunningRecognize` method."],["LongRunningRecognizeResponse","The only message returned to the client by the `LongRunningRecognize` method. It contains the result as zero or more sequential `SpeechRecognitionResult` messages. It is included in the `result.response` field of the `Operation` returned by the `GetOperation` call of the `google::longrunning::Operations` service."],["PhraseSet","Provides “hints” to the speech recognizer to favor specific words and phrases in the results."],["RecognitionAudio","Contains audio data in the encoding specified in the `RecognitionConfig`. Either `content` or `uri` must be supplied. Supplying both or neither returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See content limits."],["RecognitionConfig","Provides information to the recognizer that specifies how to process the request."],["RecognitionMetadata","Description of audio data to be recognized."],["RecognizeRequest","The top-level message sent by the client for the `Recognize` method."],["RecognizeResponse","The only message returned to the client by the `Recognize` method. It contains the result as zero or more sequential `SpeechRecognitionResult` messages."],["SpeakerDiarizationConfig","Config to enable speaker diarization."],["SpeechAdaptation","Speech adaptation configuration."],["SpeechContext","Provides “hints” to the speech recognizer to favor specific words and phrases in the results."],["SpeechRecognitionAlternative","Alternative hypotheses (a.k.a. n-best list)."],["SpeechRecognitionResult","A speech recognition result corresponding to a portion of the audio."],["StreamingRecognitionConfig","Provides information to the recognizer that specifies how to process the request."],["StreamingRecognitionResult","A streaming speech recognition result corresponding to a portion of the audio that is currently being processed."],["StreamingRecognizeRequest","The top-level message sent by the client for the `StreamingRecognize` method. Multiple `StreamingRecognizeRequest` messages are sent. The first message must contain a `streaming_config` message and must not contain `audio_content`. All subsequent messages must contain `audio_content` and must not contain a `streaming_config` message."],["StreamingRecognizeResponse","`StreamingRecognizeResponse` is the only message returned to the client by `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse` messages are streamed back to the client. If there is no recognizable audio, and `single_utterance` is set to false, then no messages are streamed back to the client."],["TranscriptNormalization","Transcription normalization configuration. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts."],["TranscriptOutputConfig","Specifies an optional destination for the recognition results."],["UpdateCustomClassRequest","Message sent by the client for the `UpdateCustomClass` method."],["UpdatePhraseSetRequest","Message sent by the client for the `UpdatePhraseSet` method."],["WordInfo","Word-specific information for recognized words."]]});